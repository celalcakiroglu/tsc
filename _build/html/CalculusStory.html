<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Calculus &mdash; Celal&#39;s documentation</title>
    
    <link rel="stylesheet" href="_static/better.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="Celal&#39;s documentation" href="index.html" />
    <link rel="next" title="Polygon Meshing through Triangulation" href="WebGL_Tri.html" />
    <link rel="prev" title="3D Modeling Tutorials" href="SiemensNX.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
      <link rel="stylesheet" href="_static/style.css" type="text/css" />
    <script src="_static/deneme.js" type="text/javascript"></script>
    <script src="_static/deneme2.js" type="text/javascript"></script>
    <style type="text/css">
    </style>
  </head>
  <body>
    <header id="pageheader"><h1><a href="index.html ">
        Celal's documentation
    </a></h1></header>
  <div class="related top">
  <nav id="rellinks">
    <ul>
        <li>
          &larr;
          <a href="SiemensNX.html" title="Previous document">3D Modeling Tutorials</a>
        </li>
        <li>
          <a href="WebGL_Tri.html" title="Next document">Polygon Meshing through Triangulation</a>
          &rarr;
        </li>
    </ul>
  </nav>
  <nav id="breadcrumbs">
    <ul>
      <li><a href="index.html">Home</a></li> 
    </ul>
  </nav>
  </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="calculus">
<h1>Calculus<a class="headerlink" href="#calculus" title="Permalink to this headline">¶</a></h1>
<p>I would like to start this section with the proof of a very useful formula in calculus, which is the formula for the cosine of an angle between two vectors. Once the cosine of an angle is known, the angle itself can be computed using the Math.acos() function of JavaScript. The Math.acos() function can be executed from the &#8220;Web Console&#8221; of the Firefox web browser which can be invoked by pressing &#8220;F12&#8221; or &#8220;CTRL+shift+k&#8221;.</p>
<div class="figure align-center" id="percx65">
<a class="reference internal image-reference" href="_images/twoVectors.JPG"><img alt="_images/twoVectors.JPG" src="_images/twoVectors.JPG" style="width: 357.5px; height: 286.5px;" /></a>
</div>
<div class="clearer container">
<img alt="_images/spacer.png" src="_images/spacer.png" />
</div>
<p>In the above figure, the cosines and sines of the angles <span class="math">\(\theta_a\)</span> , <span class="math">\(\theta_b\)</span> and the angle between the vectors can be expressed as follows:</p>
<div class="math">
\[\cos{\theta_a}=\frac{a_1}{\Vert \mathbf{a} \Vert},\quad \cos{\theta_b}=\frac{b_1}{\Vert \mathbf{b} \Vert},\quad
\sin{\theta_a}=\frac{a_2}{\Vert \mathbf{a} \Vert},\quad \sin{\theta_b}=\frac{b_2}{\Vert \mathbf{b} \Vert}\]</div>
<div class="math">
\[\cos(\theta_a-\theta_b)=\cos(\theta_a)\cos(\theta_b)+\sin(\theta_a)\sin(\theta_b)=\frac{a_1}{\Vert \mathbf{a} \Vert}\frac{b_1}{\Vert \mathbf{b} \Vert}+\frac{a_2}{\Vert \mathbf{a} \Vert}\frac{b_2}{\Vert \mathbf{b} \Vert}=\frac{\langle \mathbf{a} { , } \mathbf{b} \rangle}{\Vert\mathbf{a}\Vert\Vert\mathbf{b}\Vert}\]</div>
<p>where <span class="math">\(\Vert\cdot \Vert\)</span> denotes the Euclidean norm or the magnitude of a vector and <span class="math">\(\langle { \cdot { , } \cdot } \rangle\)</span> denotes the scalar product or inner product of two vectors.</p>
<div class="section" id="vector-norm-and-inner-product">
<h2>Vector norm and inner product<a class="headerlink" href="#vector-norm-and-inner-product" title="Permalink to this headline">¶</a></h2>
<p>All vectors are  denoted with bold letters. The inner product of two vectors in the Euclidean n-space <span class="math">\(\mathbb{R}^n\)</span> is defined by <span class="math">\(\langle { \mathbf{x} { , } \mathbf{y} } \rangle=\sum_{i=1}^{n}x_iy_i\)</span>. Some of the properties of the inner product are as follows [<a class="reference internal" href="#id6">6</a>]:</p>
<div class="math">
\[\lvert\langle { \mathbf{x} { , } \mathbf{y} } \rangle\rvert\leq \Vert\mathbf{x}\Vert\cdot \Vert\mathbf{y}\Vert\]</div>
<p>This can be proven using the concept of linear independence.</p>
<div class="section" id="linear-independence">
<h3>Linear independence<a class="headerlink" href="#linear-independence" title="Permalink to this headline">¶</a></h3>
<p>Let&#8217;s say we have a set of k vectors <span class="math">\(\lbrace \mathbf{v}_1, ... ,\mathbf{v}_k \rbrace\)</span> in the Euclidean n-space <span class="math">\(\mathbb{R}^n\)</span>. These vectors are either linearly dependent or independent. If there exists a set of k coefficients <span class="math">\(\lbrace\alpha_1, ... , \alpha_k \rbrace\)</span> such that not all of these coefficients are zero and <span class="math">\(\alpha_1\mathbf{v}_1 + ... +\alpha_k\mathbf{v}_k=0\)</span>, then the vectors are linearly dependent because we could express one of these vectors as a linear combination of the rest of the vectors in the set. As an example suppose that <span class="math">\(\alpha_1\neq 0\)</span>. Then we could write <span class="math">\(\mathbf{v}_1=-(\alpha_2/\alpha_1)\mathbf{v}_2-(\alpha_3/\alpha_1)\mathbf{v}_3- ... -(\alpha_k/\alpha_1)\mathbf{v}_k\)</span>. On the other hand if the only way to express the zero vector as a linear combination of these vectors is with <span class="math">\(\alpha_i=0\quad\forall i\in\lbrace 1,...,k\rbrace\)</span>, then the vectors are linearly independent. If the vectors <span class="math">\(\mathbf{x}\)</span> and <span class="math">\(\mathbf{y}\)</span> are linearly dependent, then one of them can be expressed in terms of the other such that <span class="math">\(\mathbf{x}=\alpha \mathbf{y}\)</span> for some <span class="math">\(\alpha \in\mathbb{R}\)</span>. Then we obtain:</p>
<div class="math">
\[|\langle \mathbf{x},\mathbf{y} \rangle |=|\langle \alpha \mathbf{y},\mathbf{y} \rangle|=|\alpha\langle \mathbf{y},\mathbf{y}\rangle |=|\alpha|\Vert y\Vert^2=\Vert\alpha \mathbf{y}\Vert\Vert\mathbf{y}\Vert=\Vert\mathbf{x}\Vert\Vert\mathbf{y}\Vert\]</div>
<p>On the other hand, if <span class="math">\(\mathbf{x}\)</span> and <span class="math">\(\mathbf{y}\)</span> are linearly independent, then <span class="math">\(\Vert\mathbf{x}-\alpha\mathbf{y}\Vert\neq 0\)</span> for any <span class="math">\(\alpha \in\mathbb{R}\)</span> and we obtain:</p>
<div class="math">
\[\begin{split}0&lt;\Vert\mathbf{x}-\alpha\mathbf{y}\Vert^2=\sum_{i=1}^{n}(x_i-\alpha y_i)^2=\sum_{i=1}^{n}{x_i}^2+{\alpha}^2{y_i}^2-2\alpha x_iy_i\end{split}\]</div>
<p>which is a quadratic equation in form of <span class="math">\(a{\alpha}^2+b\alpha + c\)</span>. Since this equation is always greater than zero, there are no real values of <span class="math">\(\alpha\)</span> which would make it equal to zero. As a result the discriminant of the equation (<span class="math">\(b^2-4ac\)</span>) must be less than zero. Because if it were greater than or equal to zero, then <span class="math">\({(-b \pm\sqrt{b^2-4ac})}/{2a}\)</span> would give us some real values that make the quadratic equation equal to zero. Therefore:</p>
<div class="math">
\[\begin{split}\Big(-2\sum_{i=1}^{n}x_iy_i\Big)^2-4\Big(\sum_{i=1}^n{y_i}^2\Big)\Big(\sum_{i=1}^{n}{x_i}^2\Big) &lt;0\end{split}\]</div>
<div class="math">
\[\begin{split}|\langle \mathbf{x},\mathbf{y} \rangle|^2&lt;\Vert\mathbf{y}\Vert^2\Vert\mathbf{x}\Vert^2\end{split}\]</div>
<p>This property leads to another one which is called the triangle inequality:</p>
<div class="math">
\[\Vert \mathbf{x}+\mathbf{y}\Vert\leq\Vert\mathbf{x}\Vert + \Vert \mathbf{y}\Vert\]</div>
<p>To prove this we can proceed as follows:</p>
<div class="math">
\[\begin{split}\Vert\mathbf{x}+\mathbf{y}\Vert^2&amp;=\sum_{i=1}^n(x_i+y_i)^2=\sum_{i=1}^n{x_i}^2+{y_i}^2+2x_iy_i=\Vert\mathbf{x}\Vert^2+\Vert\mathbf{y}\Vert^2+2\langle\mathbf{x},\mathbf{y}\rangle \\
&amp;\leq \Vert\mathbf{x}\Vert^2+\Vert\mathbf{y}\Vert^2+2\Vert\mathbf{x}\Vert\Vert\mathbf{y}\Vert=(\Vert\mathbf{x}\Vert+\Vert\mathbf{y}\Vert)^2\end{split}\]</div>
<p>Now let&#8217;s turn back to the vectors <span class="math">\(\mathbf{a}\)</span>, <span class="math">\(\mathbf{b}\)</span> in <span class="math">\(\mathbb{R}^2\)</span> and the angle between them. The formula for the cosine of the difference between two angles(or an angle between two vectors) can be derived as follows[<a class="reference internal" href="#id1">1</a>]:</p>
<p>Let <span class="math">\(f(\theta)=\cos(\theta-\beta)+\alpha_1\cos(\theta)+\alpha_2\sin(\theta)\)</span> where <span class="math">\(f:\mathbb{R}\to\mathbb{R}\)</span> and <span class="math">\(\beta,\alpha_1, \alpha_2 \in \mathbb{R}\)</span> are arbitrary. The first and second derivatives of <span class="math">\(f(\theta)\)</span> look like:</p>
<div class="math">
\[\begin{split}&amp;f^{'}(\theta)=-\sin(\theta-\beta)-\alpha_1\sin(\theta)+\alpha_2\cos(\theta)\\
&amp;f^{''}(\theta)=-\cos(\theta-\beta)-\alpha_1\cos(\theta)-\alpha_2\sin(\theta)\end{split}\]</div>
<p>from which</p>
<div class="math">
\[f(\theta)+f^{''}(\theta)=0\]</div>
<p>follows. If we choose <span class="math">\(\alpha_1\)</span> and <span class="math">\(\alpha_2\)</span> as</p>
<div class="math">
\[\alpha_1=-\cos(\beta), \alpha_2=-\sin(\beta)\]</div>
<p>we obtain</p>
<div class="math">
\[f(\theta)=\cos(\theta-\beta)-\cos(\theta)\cos(\beta)-\sin(\theta)\sin(\beta)\]</div>
<div class="math">
\[f(0)=f^{'}(0)=0\]</div>
<p>Let&#8217;s define <span class="math">\(g:\mathbb{R}\to\mathbb{R}\)</span> as <span class="math">\(g(\theta)=(f(\theta))^2+(f^{'}(\theta))^2\)</span>. Then</p>
<div class="math">
\[g^{'}(\theta)=2f(\theta)f^{'}(\theta)+2f^{'}(\theta)f^{''}(\theta)=2f^{'}(\theta)\Big(f(\theta)+f^{''}(\theta)\Big)=0\]</div>
<p>Since <span class="math">\(g^{'}(\theta)=0\)</span> for all <span class="math">\(\theta\in\mathbb{R}\)</span>, <span class="math">\(g(\theta)\)</span> is a constant function and equal to <span class="math">\(g(0)=(f(0))^2+(f^{'}(0))^2=0\)</span> for all <span class="math">\(\theta\in\mathbb{R}\)</span>. Assume that <span class="math">\(f(\theta_0)\neq 0\)</span> for some <span class="math">\(\theta_0 \in\mathbb{R}\)</span>. Then <span class="math">\(g(\theta_0)=(f(\theta_0))^2+(f^{'}(\theta_0))^2&gt;0\)</span>. This contradiction proves that <span class="math">\(f(\theta)=0\)</span> everywhere on <span class="math">\(\mathbb{R}\)</span> and therefore <span class="math">\(\boxed{\cos(\theta-\beta)=\cos(\theta)\cos(\beta)+\sin(\theta)\sin(\beta)}\)</span>.</p>
<p>In the above proof we used the fact that if the derivative of a function is zero everywhere, then this function has a constant value. This can be proven using the mean value theorem as follows:</p>
</div>
</div>
<div class="section" id="mean-value-theorem-and-rolle-s-theorem">
<span id="mvt"></span><h2>Mean Value Theorem and Rolle&#8217;s Theorem<a class="headerlink" href="#mean-value-theorem-and-rolle-s-theorem" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math">\([a,b]\subset\mathbb{R}\)</span> with <span class="math">\(a&lt;b\)</span>. Then <span class="math">\(g(\theta)\)</span> is differentiable on <span class="math">\([a,b]\)</span>. According to the mean value theorem, there exists <span class="math">\(\xi \in (a,b)\)</span> such that</p>
<div class="math">
\[g^{'}(\xi)=\frac{g(b)-g(a)}{b-a}=0 \Rightarrow g(b)=g(a), \forall a,b \in \mathbb{R}, \quad\therefore \boxed{g(\theta)=const}\]</div>
<p>In order to prove the mean value theorem, it is possible to define another function <span class="math">\(G:\mathbb{R}\to\mathbb{R}\)</span> as <span class="math">\(G(\theta)=g(\theta)+\alpha\theta\)</span> for some <span class="math">\(\alpha\in\mathbb{R}\)</span>. Then for any interval <span class="math">\([a,b]\subset\mathbb{R}\)</span>, <span class="math">\(G(\theta)\)</span> is differentiable on <span class="math">\([a,b]\)</span>. Also, <span class="math">\(\alpha\)</span> can be chosen in such a way that <span class="math">\(G(a)=G(b)\)</span>. Since <span class="math">\(G(a)=g(a)+\alpha a\)</span> and <span class="math">\(G(b)=g(b)+\alpha b\)</span>, Choosing <span class="math">\(\alpha=(g(b)-g(a))/(a-b)\)</span> would imply that <span class="math">\(G(a)=G(b)\)</span>. Since <span class="math">\(G(\theta)\)</span> is differentiable on <span class="math">\([a,b]\)</span>, according to Rolle&#8217;s theorem, there exists <span class="math">\(\xi \in (a,b)\)</span> such that</p>
<div class="math">
\[G^{'}(\xi)=0=g^{'}(\xi)+\frac{g(b)-g(a)}{a-b}\Rightarrow \boxed{g^{'}(\xi)=\displaystyle\frac{g(b)-g(a)}{b-a}}\]</div>
<p>Once it is known that <span class="math">\(G(a)=G(b)\)</span>, there are only three possibilities for the behaviour of <span class="math">\(G(\theta)\)</span> on some point <span class="math">\(\theta_0 \in (a,b)\)</span>. The first possibility is that <span class="math">\(G(a)=G(\theta_0)=G(b)\)</span>. If this is true for any <span class="math">\(\theta_0 \in (a,b)\)</span> then <span class="math">\(G(\theta)\)</span> is constant on <span class="math">\([a,b]\)</span> and its derivative is zero at any <span class="math">\(\xi\in(a,b)\)</span> because of the definition of derivative as follows:</p>
<div class="math">
\[G^{'}(\xi)=\underset{\theta \to \xi}{\lim}\frac{G(\theta)-G(\xi)}{\theta -\xi}=\underset{\theta \to \xi}{\lim}\frac{0}{\theta -\xi}=0\]</div>
<p>The second possibility is that for some <span class="math">\(\theta_0 \in (a,b)\)</span>, <span class="math">\(G(\theta_0)&gt;G(a)=G(b)\)</span>. In this case the Weierstrass&#8217; maximum-minimum theorem guarantees the existence of some <span class="math">\(\theta_{max}\in (a,b)\)</span> such that <span class="math">\(G(\theta_{max})\geq G(\theta_0)&gt;G(a)=G(b)\)</span> and for any <span class="math">\(\theta \in (a,b)\)</span>, <span class="math">\(G(\theta)\leq G(\theta_{max})\)</span>. We also know that <span class="math">\(G^{'}(\theta_{max})\)</span> exits and is equal to the right-hand and left-hand derivatives of <span class="math">\(G\)</span> at <span class="math">\(\theta_{max}\)</span>.</p>
<div class="math">
\[0\leq\underset{\theta \to {\theta _{max}} ^{-}}{\lim}\frac{G(\theta)-G(\theta _{max})}{\theta -\theta _{max}}=G^{'}(\theta _{max})=\underset{\theta \to {\theta _{max}}^{+}}{\lim}\frac{G(\theta)-G(\theta _{max})}{\theta -\theta _{max}}\leq 0\]</div>
<p>From the above inequalities it is clear that <span class="math">\(\boxed{G^{'}(\theta _{max})=0}\)</span>. This completes the proof of Rolle`s theorem since the only remaining possibility is that for some <span class="math">\(\theta_0 \in (a,b)\)</span>, <span class="math">\(G(\theta_0)&lt;G(a)=G(b)\)</span> and the proof of this case is identical to the previous case.</p>
</div>
<div class="section" id="taylor-s-theorem">
<h2>Taylor&#8217;s theorem<a class="headerlink" href="#taylor-s-theorem" title="Permalink to this headline">¶</a></h2>
<p>A generalization of the <strong>mean value theorem</strong> to n times differentiable functions is <strong>Taylor&#8217;s theorem</strong>. According to Taylor&#8217;s theorem, if <span class="math">\(f^{(n-1)}(x)\)</span> exists on [a,b] and <span class="math">\(f^n(x)\)</span> exists on (a,b), then there exists <span class="math">\(\xi \in (a,b)\)</span> such that</p>
<div class="math">
\[f(b)=\sum_{k=0}^{n-1}\frac{f^{(k)}(a)}{k!}(b-a)^k + \frac{f^{n}(\xi)}{n!}(b-a)^n\]</div>
<p>In order to prove this, we define the following function <span class="math">\(\phi(x)\)</span> [<a class="reference internal" href="#id2">2</a>] :</p>
<div class="math">
\[\phi(x)=\sum_{k=0}^{n-1}\frac{f^{(k)}(x)}{k!}(b-x)^k + M(b-x)^n\]</div>
<p>Clearly <span class="math">\(\phi\)</span> is continuous on [a,b] and differentiable on (a,b). Therefore if we choose a value for M such that <span class="math">\(\phi(a)=\phi(b)=f(b)\)</span>, then from Rolle&#8217;s theorem [<a class="reference internal" href="#mvt">mvt</a>] it would follow that there exists <span class="math">\(\xi\in (a,b)\)</span> such that <span class="math">\(\phi'(\xi)=0\)</span>.</p>
<div class="math">
\[\begin{split}\phi'(x)&amp;=f'(x)+\sum_{k=1}^{n-1}\frac{f^{(k+1)}(x)}{k!}(b-x)^k - \frac{f^{(k)}(x)}{k!}k(b-x)^{(k-1)} - Mn(b-x)^{(n-1)} \\
&amp;=f'(x)+\sum_{k=2}^{n}\frac{f^{(k)}(x)}{(k-1)!}(b-x)^{k-1}-\sum_{k=1}^{n-1}\frac{f^{(k)}(x)}{(k-1)!}(b-x)^{k-1}-Mn(b-x)^{n-1}\\
&amp;=f'(x)-f'(x)+\frac{f^{(n)}(x)}{(n-1)!}(b-x)^{n-1}-Mn(b-x)^{n-1}\\\end{split}\]</div>
<div class="math">
\[\phi'(\xi)=0\Rightarrow \frac{f^{(n)}(\xi)}{(n-1)!}(b-\xi)^{n-1}=Mn(b-\xi)^{n-1}\Rightarrow M=\frac{f^{(n)}(\xi)}{n!}\]</div>
<p>Inserting the above found M into the expression <span class="math">\(\phi(a)=\phi(b)\)</span> completes the proof of Taylor&#8217;s theorem.</p>
<p>Taylor&#8217;s theorem can also be expressed in <strong>integral form</strong> using the fundamental theorem of calculus which says that if a function <span class="math">\(f(x)\)</span> is differentiable on <span class="math">\([a,b]\)</span> and <span class="math">\(\int_a^b f'(x)dx\)</span> exists, then <span class="math">\(f(b)-f(a)=\int_a^b f'(x)dx\)</span>. This expression can be reformulated as</p>
<div class="math">
\[f(b)=\frac{1}{0!}f(a)(b-a)^0+\frac{1}{0!}\int_a^bf'(x)dx=p_0+r_0\]</div>
<p>Using <a class="reference internal" href="#integration-by-parts">integration by parts</a>, the <span class="math">\(r_0\)</span> part of the above equation can be expanded as follows:</p>
<div class="math">
\[\begin{split}r_0&amp;=-\frac{1}{1!}\int_a^bf'(x)d(b-x)\\
   &amp;u=f'(x), du=f''(x)dx,\quad dv=d(b-x), v=b-x \\
   &amp;=-\frac{1}{1!}\Big[f'(x)(b-x)\Big|_a^b-\int_a^bf''(x)(b-x)dx\Big]\\
   &amp;=-\frac{1}{1!}\Big[-f'(a)(b-a)-\int_a^bf''(x)(b-x)dx\Big]\\
   &amp;=\frac{1}{1!}f'(a)(b-a)^1+\frac{1}{1!}\int_a^bf''(x)(b-x)dx\end{split}\]</div>
<p>which gives us</p>
<div class="math">
\[p_1=\frac{1}{0!}f^{(0)}(a)(b-a)^0+\frac{1}{1!}f^{(1)}(a)(b-a)^1,\quad r_1=\frac{1}{1!}\int_a^bf^{(2)}(x)(b-x)^1dx\]</div>
<p>Continuing this way, if <span class="math">\(f^{(n+1)}(x)\)</span> is continuous on <span class="math">\([a,b]\)</span>, then we would obtain</p>
<div class="math">
\[p_n=\sum_{k=0}^{n}\frac{f^{(k)}(a)}{k!}(b-a)^k,\quad r_n=\frac{1}{n!}\int_a^bf^{(n+1)}(x)(b-x)^ndx\]</div>
<p>In order to show this inductively, we can expand <span class="math">\(r_n\)</span> as follows</p>
<div class="math">
\[\begin{split}r_n&amp;=-\frac{1}{(n+1)!}\int_a^bf^{(n+1)}(x)d(b-x)^{(n+1)}\\
   &amp;=-\frac{1}{(n+1)!}\Big[f^{(n+1)}(x)(b-x)^{(n+1)}\Big|_a^b-\int_a^bf^{(n+2)}(x)(b-x)^{(n+1)}dx\Big]\\
   &amp;=\frac{1}{(n+1)!}f^{(n+1)}(a)(b-a)^{(n+1)}+\frac{1}{(n+1)!}\int_a^bf^{(n+2)}(x)(b-x)^{(n+1)}dx\end{split}\]</div>
<p>which gives us</p>
<div class="math">
\[p_{n+1}=\sum_{k=0}^{n+1}\frac{f^{(k)}(a)}{k!}(b-a)^k,\quad r_{n+1}=\frac{1}{(n+1)!}\int_a^bf^{(n+2)}(x)(b-x)^{(n+1)}dx\]</div>
<p>Therefore, if <span class="math">\(f^{(n)}(x)\)</span> is continuous on <span class="math">\([a,b]\)</span>, then <strong>the integral form of Taylor&#8217;s theorem</strong> is</p>
<div class="math">
\[f(b)=\sum_{k=0}^{n-1}\frac{f^{(k)}(a)}{k!}(b-a)^k+\frac{1}{(n-1)!}\int_a^bf^{(n)}(a)(b-a)^{(n-1)}dx\]</div>
</div>
<div class="section" id="integration-by-parts">
<h2>Integration by Parts<a class="headerlink" href="#integration-by-parts" title="Permalink to this headline">¶</a></h2>
<p>We used this integration rule while deriving the integral form of <a class="reference internal" href="#taylor-s-theorem">Taylor&#8217;s theorem</a>. The rule is based on <a class="reference internal" href="#the-fundamental-theorem-of-calculus">the fundamental theorem of calculus</a> which says that if <span class="math">\(f,g\)</span> are differentiable functions and <span class="math">\(f',g'\)</span> are integrable on <span class="math">\([a,b]\)</span> then <span class="math">\(\int_a^b(f(x)g(x))'dx=f(x)g(x)|_a^b\)</span>.</p>
<p>Using <a class="reference internal" href="#the-product-rule">the product rule</a> for differentiation we obtain:</p>
<div class="math">
\[\begin{split}&amp;\int_a^b(f(x)g(x))'dx=\int_a^b\Big[f'(x)g(x)+f(x)g'(x)\Big]dx=f(x)g(x)|_a^b\\
&amp;\Rightarrow \int_a^bf(x)g'(x)dx=f(x)g(x)|_a^b-\int_a^bg(x)f'(x)dx\end{split}\]</div>
<p>If we let <span class="math">\(f(x)=u\)</span>, <span class="math">\(g(x)=v\)</span>, this rule can also be expressed as <span class="math">\(\int_a^b udv=uv|_a^b-\int_a^bvdu\)</span>.</p>
</div>
<div class="section" id="power-series">
<h2>Power Series<a class="headerlink" href="#power-series" title="Permalink to this headline">¶</a></h2>
<p>Series in the form of the Taylor expansion of a function <span class="math">\(f:[a,b]\to\mathbb{R}\)</span> at <span class="math">\(b\)</span> about <span class="math">\(a\)</span> are called power series. Furthermore, for every power series <span class="math">\(\sum_{k=n}^\infty c_k(x-a)^k\)</span> there is a certain set of values such that if <span class="math">\(|x|\)</span> is in that set then the series absolutely converges and if it is not then the series diverges. This set is defined by the concept of <a class="reference internal" href="#radius-of-convergence">radius of convergence</a>. Before proving that every power series has a radius of convergence, first let&#8217;s clarify the concept of absolute convergence and show that absolutely convergent series are a subset of convergent series.</p>
<p>A series in the form <span class="math">\(\sum_{k=n_0}^\infty a_k\)</span> is absolutely convergent if the series <span class="math">\(\sum_{k=n_0}^\infty |a_k|\)</span> is convergent. To show this we use a property of the absolute value operator which states that if <span class="math">\(x,c\in\mathbb{R}\)</span> and <span class="math">\(c\geq 0\)</span> then <span class="math">\(|x|\leq c\)</span> if and only if <span class="math">\(-c\leq x\leq c\)</span>. Using this we obtain <span class="math">\(-|a_k|\leq a_k \leq |a_k|\)</span> and <span class="math">\(0\leq a_k+|a_k|\leq 2|a_k|\)</span>. According to the <a class="reference internal" href="#direct-comparison-test">direct comparison test</a> for the convergence of series, if <span class="math">\(\sum_{k=n_0}^\infty |a_k|\)</span> converges then <span class="math">\(\sum_{k=n_0}^\infty 2|a_k|\)</span> converges and <span class="math">\(\sum_{k=n_0}^\infty a_k+|a_k|\)</span> converges. We know that <span class="math">\(\sum_{k=n_0}^\infty a_k=\sum_{k=n_0}^\infty a_k+|a_k|-|a_k|=\sum_{k=n_0}^\infty a_k+|a_k|-\sum_{k=n_0}^\infty |a_k|\)</span>. This means that <span class="math">\(\sum_{k=n_0}^\infty a_k\)</span> is the sum of two convergent series and therefore is itself convergent.</p>
<div class="section" id="direct-comparison-test">
<h3>Direct Comparison Test<a class="headerlink" href="#direct-comparison-test" title="Permalink to this headline">¶</a></h3>
<p>This test is used in order to determine the convergence behaviour of a series <span class="math">\(\sum_{k=n_0}^\infty |a_k|\)</span> based on the behaviour of another series <span class="math">\(\sum_{k=n_0}^\infty |b_k|\)</span>. If there exists <span class="math">\(N\in \mathbb{N}\)</span> such that <span class="math">\(\forall k\geq N\)</span>, <span class="math">\(0\leq a_k\leq b_k\)</span>, then <span class="math">\(\sum_{k=n_0}^\infty |b_k|\)</span> is convergent <span class="math">\(\Rightarrow\)</span> <span class="math">\(\sum_{k=n_0}^\infty |a_k|\)</span> is convergent and if <span class="math">\(\sum_{k=n_0}^\infty |a_k|\)</span> is divergent <span class="math">\(\Rightarrow\)</span><span class="math">\(\sum_{k=n_0}^\infty |b_k|\)</span> is divergent. Let <span class="math">\(M_a=\sum_{k=n_0}^N a_k\)</span>, <span class="math">\(M_b=\sum_{k=n_0}^N b_k\)</span>. Then <span class="math">\(\sum_{k=n_0}^\infty a_k=M_a+\sum_{k=N+1}^\infty a_k\)</span> and <span class="math">\(\sum_{k=n_0}^\infty b_k=M_b+\sum_{k=N+1}^\infty b_k\)</span>. Let <span class="math">\(\forall n&gt;N\)</span>,
<span class="math">\(S_n=\sum_{k=N+1}^n a_k\)</span> and <span class="math">\(T_n=\sum_{k=N+1}^n b_k\)</span>. If <span class="math">\(\sum_{k=n_0}^\infty b_k\)</span> is a convergent series, then <span class="math">\(\lbrace T_n \rbrace\)</span> must be a convergent and therefore bounded sequence. As a result <span class="math">\(\lbrace S_n \rbrace\)</span> is bounded. Since <span class="math">\(a_k\)</span> is non-negative for <span class="math">\(k\geq N\)</span>, <span class="math">\(\lbrace S_n \rbrace\)</span> is also a monotonely increasing sequence. Therefore <span class="math">\(\lbrace S_n \rbrace\)</span> is convergent and <span class="math">\(\sum_{k=n_0}^\infty a_k=M_a+\lim_{n\to\infty}S_n\)</span>.</p>
<p>Assume that <span class="math">\(\sum_{k=n_0}^\infty a_k\)</span> is divergent but <span class="math">\(\sum_{k=n_0}^\infty b_k\)</span> is convergent. Then <span class="math">\(\lbrace T_n\rbrace\)</span> must be convergent and bounded which implies the boundedness and convergence of <span class="math">\(\lbrace S_n \rbrace\)</span> and <span class="math">\(\sum_{k=n_0}^\infty a_k\)</span>. This contradiction proves the divergence of <span class="math">\(\sum_{k=n_0}^\infty b_k\)</span>.</p>
</div>
<div class="section" id="every-convergent-sequence-is-bounded">
<h3>Every convergent sequence is bounded<a class="headerlink" href="#every-convergent-sequence-is-bounded" title="Permalink to this headline">¶</a></h3>
<p>While proving why direct comparison test works we used the fact that convergent sequences must be bounded. Let <span class="math">\(a_n\to L\)</span>. <span class="math">\(\exists N\in\mathbb{N}:n\geq N \Rightarrow |a_n-L|&lt;1\Rightarrow|a_n|&lt;1+|L|\)</span> where we are using another property of the absolute value operator which is as follows: <span class="math">\(\Big||x|-|y|\Big|\leq |x-y|,\forall x,y\in\mathbb{R}\)</span>. Let <span class="math">\(M=\max\lbrace|a_1|, |a_2|, ... , |a_{N-1}|,1+|L|\rbrace\)</span>. Then <span class="math">\(\forall n,|a_n|\leq M\)</span> and <span class="math">\(\lbrace a_n\rbrace\)</span> is bounded.</p>
</div>
<div class="section" id="limit-comparison-test">
<h3>Limit Comparison Test<a class="headerlink" href="#limit-comparison-test" title="Permalink to this headline">¶</a></h3>
<p>[<a class="reference internal" href="#id4">4</a>]Let <span class="math">\(\lim_{n\to\infty}\frac{a_n}{b_n}=L\)</span> and <span class="math">\(0&lt; a_n, b_n\)</span> for <span class="math">\(n\)</span> greater than or equal to some <span class="math">\(N\in\mathbb{N}\)</span>. If <span class="math">\(0&lt;L&lt;\infty\)</span>, then either both <span class="math">\(\sum_{n=0}^\infty a_n\)</span> and <span class="math">\(\sum_{n=0}^\infty b_n\)</span> converge or both diverge.</p>
<p>For large enough <span class="math">\(n\)</span>, <span class="math">\(a_n,b_n&gt;0\)</span> and <span class="math">\(\displaystyle\frac{L}{2}&lt;\frac{a_n}{b_n}&lt;\frac{3L}{2}\Rightarrow \frac{L}{2}b_n&lt;a_n&lt;\frac{3L}{2}b_n\)</span>. Therefore by <a class="reference internal" href="#direct-comparison-test">direct comparison test</a> either both <span class="math">\(\sum_{n=0}^\infty a_n\)</span> and <span class="math">\(\sum_{n=0}^\infty b_n\)</span> converge or both diverge.</p>
<p>If <span class="math">\(L=0\)</span> then for large enough <span class="math">\(n\)</span>, <span class="math">\(a_n,b_n&gt;0\)</span> and <span class="math">\(\frac{a_n}{b_n}&lt;1\Rightarrow 0&lt;a_n&lt;b_n\)</span>. It follows that if <span class="math">\(\sum_{n=0}^\infty b_n\)</span> is convergent then <span class="math">\(\sum_{n=0}^\infty a_n\)</span> is convergent.</p>
<p>If <span class="math">\(L=\infty\)</span> then for large enough <span class="math">\(n\)</span>, <span class="math">\(a_n,b_n&gt;0\)</span> and <span class="math">\(1&lt;\frac{a_n}{b_n}\Rightarrow 0&lt;b_n&lt;a_n\)</span>. It follows that if <span class="math">\(\sum_{n=0}^\infty b_n\)</span> is divergent then <span class="math">\(\sum_{n=0}^\infty a_n\)</span> is divergent.</p>
</div>
<div class="section" id="ratio-test">
<h3>Ratio Test<a class="headerlink" href="#ratio-test" title="Permalink to this headline">¶</a></h3>
<p>[<a class="reference internal" href="#id4">4</a>]Let <span class="math">\(a_n&gt;0\)</span> for all <span class="math">\(n\)</span> and <span class="math">\(\lim_{n\to\infty}\frac{a_{n+1}}{a_n}=\rho\)</span>. If <span class="math">\(\rho&lt;1\)</span> then the series <span class="math">\(\sum_{n=n_0}^\infty a_n\)</span> converges, if <span class="math">\(\rho&gt;1\)</span> then the series diverges and if <span class="math">\(\rho=1\)</span> then the test is inconclusive. First, let
us investigate the case when <span class="math">\(\rho&lt;1\)</span>. Let <span class="math">\(\rho&lt;r&lt;1\)</span>. Then there exists <span class="math">\(N\in\mathbb{N}\)</span> such that if <span class="math">\(n\geq N\)</span> then <span class="math">\(\frac{a_{n+1}}{a_n}-\rho &lt;r-\rho\Rightarrow \frac{a_{n+1}}{a_n} &lt;r\)</span>. It follows that</p>
<div class="math">
\[\begin{split}a _{N+1}&lt;ra_N\end{split}\]</div>
<div class="math">
\[\begin{split}a _{N+2}&lt;ra _{N+1}&lt;r^2 a_N\end{split}\]</div>
<div class="math">
\[\begin{split}\Rightarrow a _{N+k}&lt;r^k a_N\end{split}\]</div>
<p>Since <span class="math">\(|r|&lt;1\)</span>, <span class="math">\(a_N\sum_{k=1}^\infty r^k\)</span> is a convergent series and by the <a class="reference internal" href="#direct-comparison-test">direct comparison test</a> <span class="math">\(\sum_{k=N+1}^\infty a_k\)</span> is a convergent series. Considering that <span class="math">\(\sum_{k=0}^N a_k\)</span> is a finite value, we can conclude that <span class="math">\(\sum_{k=0}^\infty a_k\)</span> is convergent when <span class="math">\(\rho&lt;1\)</span>.</p>
<p>If <span class="math">\(\rho&gt;1\)</span> then for all large <span class="math">\(n\)</span>, <span class="math">\(0&lt;a_n&lt;a_{n+1}\)</span> and <span class="math">\(\lbrace a_n \rbrace\)</span> does not converge to zero which implies that in this case <span class="math">\(\sum_{n=0}^\infty a_n\)</span> is divergent.</p>
<p>In both cases <span class="math">\(a_n=1/n\)</span> and <span class="math">\(a_n=1/n^2\)</span>, <span class="math">\(\displaystyle\frac{a_{n+1}}{a_n}\to 1\)</span> but the first of these series is divergent and the second one is convergent. Therefore, the test is inconclusive if <span class="math">\(\rho=1\)</span>.</p>
</div>
<div class="section" id="root-test">
<h3>Root Test<a class="headerlink" href="#root-test" title="Permalink to this headline">¶</a></h3>
<p>[<a class="reference internal" href="#id4">4</a>]Let <span class="math">\(\sqrt[n]{a_n}\to \rho\)</span> and <span class="math">\(a_n\geq 0, \forall n\geq N\)</span>. If <span class="math">\(\rho&lt;1\)</span> then <span class="math">\(\sum_{n=0}^\infty a_n\)</span> is convergent and if <span class="math">\(\rho&gt;1\)</span> then the series is divergent. In case of <span class="math">\(\rho=1\)</span> the test is inconclusive. Suppose <span class="math">\(\rho&lt;r&lt;1\)</span>. For large enough <span class="math">\(n\)</span>, <span class="math">\(\sqrt[n]{a_n}-\rho&lt;r-\rho\Rightarrow a_n&lt;r^n\)</span>. Suppose <span class="math">\(a_n&lt;r^n\)</span> for <span class="math">\(n\geq K&gt;N\)</span>. Let <span class="math">\(M_a=\sum_{n=0}^{K-1}a_n\)</span> and compare the series <span class="math">\(\sum_{n=N}^\infty a_n\)</span> and <span class="math">\(\sum_{n=N}^\infty r^n\)</span>. Since <span class="math">\(|r|&lt;1\)</span>, the geometric series <span class="math">\(\sum_{n=N}^\infty r^n\)</span> converges to <span class="math">\(1/(1-r)\)</span> and by the <a class="reference internal" href="#direct-comparison-test">direct comparison test</a> <span class="math">\(\sum_{n=N}^\infty a_n\)</span> and therefore <span class="math">\(\sum_{n=0}^\infty a_n\)</span> are convergent. On the other hand if <span class="math">\(\rho&gt;1\)</span> then for all large <span class="math">\(n\)</span>, <span class="math">\((a_n)^{(1/n)}&gt;1\Rightarrow a_n&gt;1\)</span> which means that <span class="math">\(a_n\)</span> does not converge to 0 and therefore the series diverges. In order to prove the inconclusiveness of the test when <span class="math">\(\rho=1\)</span>, consider the series <span class="math">\(\sum_{n=1}^{\infty}1/n\)</span> and <span class="math">\(\sum_{n=1}^{\infty}1/n^2\)</span>. In both cases <span class="math">\(a_n\to 1\)</span> but the first series is divergent whereas the second is convergent.</p>
</div>
<div class="section" id="dirichlet-test">
<h3>Dirichlet Test<a class="headerlink" href="#dirichlet-test" title="Permalink to this headline">¶</a></h3>
<p>[<a class="reference internal" href="#id2">2</a>] Let <span class="math">\(a_k\to 0\)</span> and <span class="math">\(S_n=\sum_{k=0}^\infty b_k\)</span> is a bounded sequence such that for every <span class="math">\(n\)</span>, <span class="math">\(|S_n|\leq B\)</span>. Furthermore the sequence <span class="math">\(\lbrace a_k\rbrace\)</span> is of bounded variation which means that <span class="math">\(\lim_{k=1}^\infty |a_{k+1}-a_k|\)</span> is convergent. Then <span class="math">\(\sum_{k=1}^\infty a_kb_k\)</span> is convergent.</p>
<p>Let <span class="math">\(\varepsilon&gt;0\)</span>. There exists <span class="math">\(N\)</span> such that whenever <span class="math">\(n,m\geq N\)</span>, <span class="math">\(\sum_n^m|a_{k+1}-a_k|&lt;\frac{\varepsilon}{3B}\)</span> by the Cauchy convergence criterion. Also whenever <span class="math">\(k\geq N\)</span>, <span class="math">\(|a_k|&lt;\frac{\varepsilon}{3B}\)</span>.</p>
<p>Let <span class="math">\(n,m \geq N\)</span>. Using <a class="reference internal" href="#abel-s-lemma">Abel&#8217;s lemma</a> :</p>
<div class="math">
\[\begin{split}\Big|\sum_{k=n}^m a_kb_k \Big|&amp;=\Big|\sum_{k=n}^ma_k(S_k-S_{k-1})\Big|\\
   &amp;=\Big| a_{m+1}S_m-a_nS_{n-1}-\sum_{k=n}^m (a_{k+1}-a_k)S_k\Big|\\
   &amp;\leq\Big| a_{m+1}S_m\Big|+\Big|a_nS_{n-1}\Big|+\Big|\sum_{k=n}^m (a_{k+1}-a_k)S_k\Big|\\
   &amp;\leq\Big| a_{m+1}\Big|\Big|S_m\Big|+\Big|a_n\Big|\Big|S_{n-1}\Big|+\Big|S_k\Big|\Big|\sum_{k=n}^m (a_{k+1}-a_k)\Big|\\
   &amp;&lt;\frac{\varepsilon}{3B}B+\frac{\varepsilon}{3B}B+\frac{\varepsilon}{3B}B=\varepsilon\end{split}\]</div>
<p>Therefore <span class="math">\(\sum_{k=0}^\infty a_kb_k\)</span> is convergent according to the Cauchy convergence criterion.</p>
</div>
<div class="section" id="cauchy-convergence-criterion">
<h3>Cauchy convergence criterion<a class="headerlink" href="#cauchy-convergence-criterion" title="Permalink to this headline">¶</a></h3>
<p>[<a class="reference internal" href="#id1">1</a>] This criterion says that a sequence is convergent if and only if it is a Cauchy sequence. A sequence is called Cauchy sequence, if for every <span class="math">\(\varepsilon\)</span>, there exists <span class="math">\(N\in\mathbb{N}\)</span> such that whenever <span class="math">\(n,m\geq N\)</span>, <span class="math">\(|a_n-a_m|&lt;\varepsilon\)</span>.</p>
<p>If <span class="math">\(a_n\to L\)</span> and <span class="math">\(\varepsilon&gt;0\)</span>. There exists <span class="math">\(N\in\mathbb{N}\)</span> such that <span class="math">\(n,m\geq N\Rightarrow |a_n-L|&lt;\varepsilon/2\)</span> and <span class="math">\(|a_m-L|&lt;\varepsilon/2\)</span>. Therefore <span class="math">\(|a_n-a_m|=|a_n-L+L-a_m|\leq |a_n-L|+|a_m-L|&lt;\varepsilon/2+\varepsilon/2=\varepsilon\)</span>.</p>
<p>Conversely, if <span class="math">\(\lbrace a_n\rbrace\)</span> is a Cauchy sequence, then first of all it is a bounded sequence. We know that there exists <span class="math">\(N\in\mathbb{N}\)</span> such that <span class="math">\(n,m\geq N\Rightarrow|a_n-a_m|&lt;1\Rightarrow |a_n|&lt;1+|a_N|\)</span>. Let <span class="math">\(M=\max\lbrace|a_1|,|a_2|, ... ,|a_{N-1}|, 1+|a_N|\rbrace\)</span>. Then <span class="math">\(\lbrace a_n \rbrace\)</span> is bounded by <span class="math">\(M\)</span>. Since <span class="math">\(\lbrace a_n \rbrace\)</span> is bounded, it has a convergent subsequence <span class="math">\(a_{n_k}\to c\)</span>. Let <span class="math">\(\varepsilon &gt;0\)</span>. For some <span class="math">\(N\)</span>, <span class="math">\(|a_n-a_m|\)</span> is always less than <span class="math">\(\varepsilon/2\)</span> if <span class="math">\(n,m\geq N\)</span>. Also there exists <span class="math">\(K&gt;N\)</span> such that if <span class="math">\(k\geq K\)</span>, then <span class="math">\(|a_{n_k}-c|&lt;\varepsilon/2\)</span>. Let <span class="math">\(n\geq N\)</span> and <span class="math">\(k\geq K\)</span>. Considering that <span class="math">\(n_k\geq k\)</span>, we obtain <span class="math">\(|a_n-c|=|a_n-a_{n_k}+a_{n_k}-c|\leq|a_n-a_{n_k}|+|a_{n_k}-c|&lt;\varepsilon/2+\varepsilon/2=\varepsilon\)</span>. This proves that every Cauchy sequence is a convergent sequence.</p>
</div>
<div class="section" id="abel-s-lemma">
<h3>Abel&#8217;s Lemma<a class="headerlink" href="#abel-s-lemma" title="Permalink to this headline">¶</a></h3>
<p>[<a class="reference internal" href="#id2">2</a>]This lemma states that <span class="math">\(\sum_n^ma_k(b_{k+1}-b_k)=a_{m+1}b_{m+1}-a_nb_n-\sum_n^m(a_{k+1}-a_k)b_{k+1}\)</span>. This can be proven as follows:</p>
<div class="math">
\[\begin{split}\sum_n^m a_k (b _{k+1}-b_k)&amp;=\sum_n^ma_k b _{k+1}-\sum_n^m a_k b_k \\
&amp;=\sum_n^ma_k b _{k+1}-\sum _{n+1}^{m+1} a_k b_k +a _{m+1}b _{m+1}-a_nb_n \\
&amp;=\sum_n^m \Big[a _k b _{k+1}-a _{k+1}b _{k+1}\Big]+a _{m+1}b _{m+1}-a_nb_n \\
&amp;=\sum_n^m b _{k+1}\Big[ a_k-a _{k+1} \Big]+  a _{m+1}b _{m+1}-a_nb_n \\
&amp;=a _{m+1}b _{m+1}-a_nb_n-\sum_n^m(a _{k+1}-a_k)b _{k+1}\end{split}\]</div>
</div>
<div class="section" id="radius-of-convergence">
<h3>Radius of convergence<a class="headerlink" href="#radius-of-convergence" title="Permalink to this headline">¶</a></h3>
<p>[<a class="reference internal" href="#id2">2</a>]For every power series there exists a value <span class="math">\(R\)</span> called the radius of convergence such that <span class="math">\(0\leq R\leq \infty\)</span>. If <span class="math">\(|x|&lt;R\)</span> then the series <span class="math">\(\sum_{k=n_0}^\infty c_k(x-a)^k\)</span> absolutely converges and if <span class="math">\(|x|&gt;R\)</span> then the series diverges.</p>
<p>Consider a convergent series <span class="math">\(\sum_{k=n_0}^\infty c_k(x_0-a)^k\)</span> and let <span class="math">\(|x-a|&lt;|x_0-a|\)</span>. For the sake of convenience let <span class="math">\(y=x-a\)</span> and <span class="math">\(y_0=x_0-a\)</span>. Since <span class="math">\(\sum_{k=n_0}^\infty c_k{y_0}^k\)</span> is convergent, there exists a real number <span class="math">\(M\)</span> such that <span class="math">\(|c_k{y_0}^k|\leq M\)</span> for all <span class="math">\(k\)</span>. Then <span class="math">\(|c_ky^k|=|c_ky_0^k|\displaystyle\frac{|c_ky^k|}{|c_k{y_0}^k|}\leq M \displaystyle\frac{|y^k|}{|{y_0}^k|}\)</span>. Since <span class="math">\(\displaystyle\frac{y}{y_0}&lt;1\)</span>, the right hand side of the inequality is a convergent geometric series and using the <a class="reference internal" href="#direct-comparison-test">direct comparison test</a> we obtain that <span class="math">\(\sum_{k=n_0}^\infty c_ky^k\)</span> absolutely converges.</p>
<p>Let <span class="math">\(S=\lbrace r\geq 0:\sum_{k=n_0}^\infty c_kr^k \text{ is convergent}\rbrace\)</span>. If <span class="math">\(S\)</span> is unbounded, then for every <span class="math">\(y\in \mathbb{R}\)</span> there exists <span class="math">\(r\in S\)</span> such that <span class="math">\(|y|&lt;|r|\)</span> and <span class="math">\(\sum_{k=n_0}^\infty c_ky^k\)</span> is absolutely convergent. This means that the series is absolutely convergent for <span class="math">\(|y|&lt;\infty\)</span> or <span class="math">\(|x|&lt;\infty\)</span>. If <span class="math">\(S\)</span> is bounded then using the completeness axiom of the set of real numbers we know that it has a supremum. Let <span class="math">\(R=\sup S\)</span> and <span class="math">\(|y|&lt;R\)</span>. Then, there exists <span class="math">\(r\in S\)</span> such that <span class="math">\(|y|&lt;r\leq |r|\)</span> otherwise <span class="math">\(|y|\)</span> would be the supremum. It follows that <span class="math">\(\sum_{k=n_0}^\infty c_ky^k\)</span> is absolutely convergent when <span class="math">\(|y|&lt;R\)</span>. This means that <span class="math">\(\sum_{k=n_0}^\infty c_k(x-a)^k\)</span> is absolutely convergent when <span class="math">\(x\in(-R+a,R+a)\)</span>. As another possibility, suppose that <span class="math">\(R&lt;|y|\)</span>. Then there exists some <span class="math">\(r\)</span> such that <span class="math">\(R&lt;r&lt;|y|\)</span>. Assume that <span class="math">\(\sum_{k=n_0}^\infty c_ky^k\)</span> is convergent. Then <span class="math">\(\sum_{k=n_0}^\infty c_k r^k\)</span> must be absolutely convergent and therefore convergent which means that <span class="math">\(r\)</span> is in <span class="math">\(S\)</span> and at the same time greater than the supremum of <span class="math">\(S\)</span>. This is a contradiction, therefore if <span class="math">\(|y|&gt;R\)</span> then <span class="math">\(\sum_{k=n_0}^\infty c_ky^k\)</span> is divergent.</p>
<p>As an example we can analyze the series <span class="math">\(\displaystyle\sum_{k=2}^\infty\frac{x^k}{\log k}\)</span>. Using the ratio test:</p>
<div class="math">
\[\lim_{k\to\infty}\Big|\frac{a_{k+1}}{a_k}\Big|=\lim_{k\to\infty}\Big|\frac{x^{k+1}\log(k+1)}{x^k\log(k)}\Big|=|x|\lim_{k\to\infty}\frac{\log(k+1)}{\log(k)}=|x|\lim_{k\to\infty}\frac{1/(k+1)}{1/k}=|x|\]</div>
<p>Therefore the series absolutely converges when <span class="math">\(|x|&lt;1\)</span> and the radius of convergence is <span class="math">\(1\)</span>. When computing the limit in the above example which includes the <a class="reference internal" href="#logarithm">logarithm</a> function we resorted to L&#8217;Hospital&#8217;s rule.</p>
</div>
</div>
<div class="section" id="l-hospital-s-rule">
<h2>L&#8217;Hospital&#8217;s Rule<a class="headerlink" href="#l-hospital-s-rule" title="Permalink to this headline">¶</a></h2>
<p>[<a class="reference internal" href="#id7">7</a>]Let <span class="math">\(f:(a,b)\to \mathbb{R}\)</span>, <span class="math">\(g:(a,b)\to \mathbb{R}\)</span> and both functions are differentiable on <span class="math">\((a,b)\)</span>.Let <span class="math">\(\displaystyle\lim_{x\to a^+}\frac{f'(x)}{g'(x)}=A\in\mathbb{R}\)</span>. Choose <span class="math">\(p,q,\varepsilon\)</span> such that <span class="math">\(A\in(p+\varepsilon,q-\varepsilon)\)</span>. Since <span class="math">\(f\)</span> and <span class="math">\(g\)</span> are differentiable on <span class="math">\((a,b)\)</span>, according to the <a class="reference internal" href="#cauchy-mean-value-theorem">Cauchy mean value theorem</a> for any <span class="math">\(x,y\in (a,b)\)</span> there exists <span class="math">\(\xi\in(x,y)\)</span> such that <span class="math">\(\displaystyle \frac{f'(\xi)}{g`(\xi)}=\frac{f(x)-f(y)}{g(x)-g(y)}\)</span>.</p>
<p>Suppose that <span class="math">\(\lim_{x\to a^+}f(x)=\lim_{x\to a^+}g(x)=0\)</span>. Since <span class="math">\(f'/g'\)</span> converges to <span class="math">\(A\)</span> as x converges to <span class="math">\(a\)</span>, there exists a neighbourhood of <span class="math">\(a\)</span> such that the intersection of that neighbourhood with <span class="math">\((a,b)\)</span> is non-empty and for every <span class="math">\(x_0\)</span> in this intersection <span class="math">\(f'(x_0)/g'(x_0)\in (p+\varepsilon,q-\varepsilon)\)</span>. Let&#8217;s call this intersection <span class="math">\((a,c)\)</span> for some <span class="math">\(c\in(a,b)\)</span>. Let <span class="math">\(x,y\in(a,c)\)</span>. Then <span class="math">\(\displaystyle\frac{f(x)-f(y)}{g(x)-g(y)}\in(p+\varepsilon,q-\varepsilon)\)</span>. Furthermore, <span class="math">\(\displaystyle\lim_{x\to a^+}\frac{f(x)-f(y)}{g(x)-g(y)}=\frac{f(y)}{g(y)}\in[p+\varepsilon,q-\varepsilon]\)</span> which means that for any neighbourhood <span class="math">\((p,q)\)</span> of <span class="math">\(A\)</span>, there exists a neighbourhood of <span class="math">\(a\)</span> such that the intersection of that neighbourhood is a non-empty set <span class="math">\((a,c)\)</span> and for every <span class="math">\(y\in(a,c)\)</span>, <span class="math">\(f(y)/g(y)\in (p,q)\)</span>. Therefore, <span class="math">\(\displaystyle\lim_{x\to a^+}\frac{f(x)}{g(x)}=A\)</span>.</p>
<p>Another case where L&#8217;Hospital&#8217;s rule can be applied is when <span class="math">\(g(x)\to\infty\)</span> as <span class="math">\(x\to a^+\)</span>. Fix <span class="math">\(y\in(a,c)\)</span>. Since <span class="math">\(g(x)\to\infty\)</span> as <span class="math">\(x\to a^+\)</span>, there exists <span class="math">\(c_1\in(a,c)\)</span> such that for every <span class="math">\(x\in(a,c_1)\)</span>, <span class="math">\(g(x)&gt;0\)</span> and <span class="math">\(g(x)&gt;g(y)\)</span>. Let <span class="math">\(x\in(a,c_1)\)</span>. Using</p>
<div class="math">
\[\begin{split}p+\varepsilon &lt;\frac{f(x)-f(y)}{g(x)-g(y)}&lt;q-\varepsilon\end{split}\]</div>
<div class="math">
\[\begin{split}\Rightarrow (p+\varepsilon)\Big(1-\frac{g(y)}{g(x)}\Big)&lt;\frac{f(x)}{g(x)}-\frac{f(y)}{g(x)}&lt;(q-\varepsilon)\Big(1-\frac{g(y)}{g(x)}\Big)\end{split}\]</div>
<div class="math">
\[\begin{split}\Rightarrow p+\varepsilon+\frac{1}{g(x)}(f(y)-(p+\varepsilon)g(y))&lt;\frac{f(x)}{g(x)}&lt;q-\varepsilon+\frac{1}{g(x)}(f(y)-(q-\varepsilon)g(y))\end{split}\]</div>
<p>Since <span class="math">\(g(x)\to\infty\)</span> as <span class="math">\(x\to a^+\)</span>, it is possible to choose <span class="math">\(x\)</span> close enough to <span class="math">\(a\)</span> and therefore <span class="math">\(g(x)\)</span> large enough such that <span class="math">\(\Big|\frac{1}{g(x)}(f(y)-(p+\varepsilon)g(y))\Big|&lt;\varepsilon\)</span>, <span class="math">\(\Big|\frac{1}{g(x)}(f(y)-(p+\varepsilon)g(y))\Big|&lt;f(x)/g(x)-(p+\varepsilon)\)</span>, <span class="math">\(\Big|\frac{1}{g(x)}(f(y)-(q-\varepsilon)g(y))\Big|&lt;\varepsilon\)</span> and <span class="math">\(\Big|\frac{1}{g(x)}(f(y)-(q-\varepsilon)g(y))\Big|&lt;q-\varepsilon-f(x)/g(x)\)</span>. Let <span class="math">\(c_2\in(a,c_1)\)</span> such that <span class="math">\(x\in(a,c_2)\)</span> satisfies these conditions. It follows that <span class="math">\(x\in(a,c_2)\Rightarrow f(x)/g(x)\in (p,q)\)</span> and <span class="math">\(\displaystyle\lim_{x\to a^+ f(x)/g(x)=A}\)</span>.</p>
</div>
<div class="section" id="cauchy-mean-value-theorem">
<h2>Cauchy Mean Value Theorem<a class="headerlink" href="#cauchy-mean-value-theorem" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math">\(f\)</span> and <span class="math">\(g\)</span> be continuous on <span class="math">\([a,b]\)</span> and differentiable on <span class="math">\((a,b)\)</span>. Then there exists <span class="math">\(\xi\in(a,b)\)</span> such that <span class="math">\(\displaystyle\frac{f'(\xi)}{g'(\xi)}=\frac{f(b)-f(a)}{g(b)-g(a)}\)</span>. In order to prove this, we can define a function <span class="math">\(\phi\)</span> as follows:</p>
<div class="math">
\[\phi(x)=(f(x)-f(a))(g(b)-g(a))-(g(x)-g(a))(f(b)-f(a))\]</div>
<p>Clearly, <span class="math">\(\phi(a)=\phi(b)=0\)</span> and from Rolle&#8217;s theorem there exists <span class="math">\(\xi\in(a,b)\)</span> such that <span class="math">\(\phi'(x)=f'(\xi)(g(b)-g(a))-g'(\xi)(f(b)-f(a))=0\Rightarrow \displaystyle\frac{f'(\xi)}{g'(\xi)}=\frac{f(b)-f(a)}{g(b)-g(a)}\)</span>.</p>
</div>
<div class="section" id="logarithm">
<h2>Logarithm<a class="headerlink" href="#logarithm" title="Permalink to this headline">¶</a></h2>
<p>The logarithm function is defined as</p>
<div class="math">
\[\log(x)=\int_1^x\frac{1}{t}dt\]</div>
<p>Using <a class="reference internal" href="#the-fundamental-theorem-of-calculus">the fundamental theorem of calculus</a> we can derive the following equality:</p>
<div class="math">
\[\begin{split}\log(xy)=\log(x)+\log(y),\quad x,y&gt;0\end{split}\]</div>
<p>Let <span class="math">\(xy=u\)</span> for <span class="math">\(x,y&gt;0\)</span>. Then <span class="math">\(\log(xy)=\log(u)=\int_1^u\frac{1}{t}dt\Rightarrow \frac{d}{dx}\log(xy)=\frac{d}{du}\log(u)\frac{du}{dx}\)</span> by <a class="reference internal" href="#the-chain-rule">the chain rule</a>. Since <span class="math">\(1/t\)</span> is continuous at <span class="math">\(t=u\)</span> we obtain <span class="math">\(\displaystyle\frac{d}{dx}\log(xy)=\frac{1}{xy}y=\frac{1}{x}\)</span>. The derivative of <span class="math">\(\log(x)\)</span> with respect to <span class="math">\(x\)</span> is also equal to <span class="math">\(\displaystyle\frac{1}{x}\)</span>. Therefore <span class="math">\(\log(xy)=\log(x)+C\)</span> where <span class="math">\(C\)</span> is a constant. Using <span class="math">\(\log(1)=0\)</span> we obtain <span class="math">\(\log(1\cdot y)=0+C\Rightarrow \log(xy)=\log(x)+\log(y)\)</span>.</p>
<p>Using the above equality we obtain <span class="math">\(0=\log(1)=\log(x\cdot x^{-1})=\log(x)+\log(x^{-1})\Rightarrow \log(x^{-1})=-\log(x)\)</span>.</p>
<p>Clearly <span class="math">\(\log(x^1)=1\cdot \log(x)\)</span>. Let <span class="math">\(n\in\mathbb{N}\)</span>. If <span class="math">\(\log(x^{n})=n\cdot \log(x)\)</span>, then <span class="math">\(\log(x^{n+1})=\log(x^n)+\log(x)=(n+1)\log(x)\therefore\forall n\in\mathbb{N},\forall x&gt;0, \log(x^n)=n\log(x)\)</span> by induction.</p>
<p><span class="math">\(\log(x^0)=0\cdot\log(x)\)</span> and <span class="math">\(\log(x^{-n})=\log((x^{-1})^n)\)</span>. Since <span class="math">\(x^{-1}&gt;0\)</span>, <span class="math">\(\log((x^{-1})^n)=n\cdot\log(x^{-1})=-n\log(x)\)</span>. Therefore for every integer <span class="math">\(m\in\mathbb{Z}\)</span>, <span class="math">\(log(x^m)=m\log(x)\)</span>.</p>
<p>Let <span class="math">\(b^n=x\Rightarrow b=x^{1/n}&gt;0\Rightarrow\log(x)=\log(b^n)=n\log(b)=n\log(x^{1/n})\)</span></p>
<p><span class="math">\(\Rightarrow\log(x^{1/n})=\frac{1}{n}\log(x)\)</span>.</p>
<p>Let <span class="math">\(q\in\mathbb{Q}\)</span> be any rational number. Then there exist an integer <span class="math">\(m\)</span> and a positive integer <span class="math">\(n\)</span> such that <span class="math">\(\log(x^q)=\log((x^{1/n})^m)=m\log(x^{1/n})=\frac{m}{n}\log(x)=q\log(x)\)</span>. Therefore for every rational number <span class="math">\(q\)</span> and for every positive real number <span class="math">\(x\)</span>, <span class="math">\(\log(x^q)=q\log(x)\)</span>.</p>
<p>While showing that the series <span class="math">\(\displaystyle\sum_{k=2}^\infty\frac{x^k}{\log k}\)</span> has the radius of convergence <span class="math">\(1\)</span>, we made use of <span class="math">\(\displaystyle\lim_{k\to\infty}\log k=\infty\)</span>. The limits of the <span class="math">\(\log\)</span> function at <span class="math">\(\pm\infty\)</span> can be obtained as follows: Let <span class="math">\((n\log(x),+\infty)\)</span> be any neighbourhood of <span class="math">\(+\infty\)</span> where <span class="math">\(n\in\mathbb{N}, 0&lt;x\in\mathbb{R}\)</span>. There exists another neighbourhood <span class="math">\((x^n,+\infty)\)</span> of <span class="math">\(+\infty\)</span> such that <span class="math">\(\forall x_0\in(x^n,+\infty),\quad \log(x^n)=n\log(x)&lt;\log(x_0)\)</span> since <span class="math">\(\log(x)\)</span> is a strictly increasing function. Therefore <span class="math">\(\log(x_0)\in (n\log(x),+\infty) \text{ and }\displaystyle\lim_{x\to+\infty} \log(x)=+\infty\)</span>.</p>
<p>Similarly, let <span class="math">\((-\infty,-n\log(x))\)</span> be any neighbourhood of <span class="math">\(-\infty\)</span> where <span class="math">\(n\in\mathbb{N}, 0&lt;x\in\mathbb{R}\)</span>. There exists a neighbourhood <span class="math">\((0,x^{-n})\)</span> of <span class="math">\(0\)</span> such that <span class="math">\(\forall x_0\in(0,x^{-n}),\quad \log(x_0)&lt;\log(x^{-n})=-n\log(x)\)</span> since <span class="math">\(\log(x)\)</span> is a strictly increasing function. Therefore <span class="math">\(\log(x_0)\in (-\infty,-n\log(x)) \text{ and }\displaystyle\lim_{x\to 0} \log(x)=-\infty\)</span>.</p>
<p>It can also be proven that the range of the <span class="math">\(\log\)</span> function is all of <span class="math">\(\mathbb{R}\)</span>. Since <span class="math">\(\log(x)\to\pm\infty,\forall r\in\mathbb{R},\exists p,q\in(0,+\infty):\log(p)&lt;r&lt;\log(q)\)</span>. Therefore according to <a class="reference internal" href="#bolzano-intermediate-value-theorem">Bolzano intermediate value theorem</a> <span class="math">\(\exists x\in(p,q):\log(x)=r\)</span>.</p>
</div>
<div class="section" id="absolute-value">
<h2>Absolute value<a class="headerlink" href="#absolute-value" title="Permalink to this headline">¶</a></h2>
<p>[<a class="reference internal" href="#id1">1</a>]Some of the most significant properties of the absolute value can be proven as follows:</p>
<p><span class="math">\(x,y\in\mathbb{R}\)</span>. <span class="math">\(-|x|\leq x\leq |x|\)</span>, <span class="math">\(-|y|\leq y\leq |y| \Rightarrow -(|x|+|y|)\leq x+y\leq(|x|+|y|)\)</span>.Also using <span class="math">\(|-y|=|y|\)</span> we obtain <span class="math">\(|x\pm y|\leq |x|+|y|\)</span>.</p>
<p><span class="math">\(|x|=|x+y-y|\leq|x+y|+|y|\Rightarrow |x|-|y|\leq|x+y|\)</span>. <span class="math">\(|y|=|y+x-x|\leq|x+y|+|x|\Rightarrow |y|-|x|\leq |x+y|\Rightarrow \Big||x|-|y|\Big|\leq|x\pm y|\leq|x|+|y|\)</span>.</p>
<p>Another property of the absolute value operator that we used in the section about the <a class="reference internal" href="#radius-of-convergence">radius of convergence</a> is that for any <span class="math">\(x,y\in \mathbb{R}\)</span>, <span class="math">\(|x|^y=|x^y|\)</span>. Using the representation of real numbers as complex numbers without imaginary part we obtain <span class="math">\(x=re^{i\theta}=|x|e^{i\theta}\)</span> and <span class="math">\(|x^y|=||x|^ye^{iy\theta}|=||x|^y||\cos(y\theta)+i\sin(y\theta)|=||x|^y|\cdot 1=|x|^y\)</span>.</p>
</div>
<div class="section" id="the-fundamental-theorem-of-calculus">
<h2>The Fundamental Theorem of Calculus<a class="headerlink" href="#the-fundamental-theorem-of-calculus" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math">\(\int_a^bf(x)dx\)</span> exist and let <span class="math">\(F:[a,b]\to\mathbb{R}\)</span> be the antiderivative of <span class="math">\(f(x)\)</span> which means that <span class="math">\(F'(x)=f(x), \forall x\in[a,b]\)</span>. Then the fundamental theorem of calculus states that <span class="math">\(F(b)-F(a)=\int_a^bf(x)dx\)</span>. In order to prove this, let <span class="math">\(P\)</span> be any partition of <span class="math">\([a,b]\)</span> so that <span class="math">\(P=\lbrace x_0=a,x_1,x_2,...,x_{n-1},x_n=b\rbrace\)</span>. Then <span class="math">\(F(b)-F(a)=\sum_{i=1}^nF(x_i)-F(x_{i-1})\)</span>. Since <span class="math">\(F(x)\)</span> is differentiable on every subinterval <span class="math">\([x_{i-1},x_i]\)</span>, according to the mean value theorem, for every <span class="math">\(i\in\lbrace 1,...,n\rbrace,\exists c_i\in(x_{i-1},x_i)\)</span> such that</p>
<div class="math">
\[F'(c_i)=f(c_i)=\frac{F(x_i)-F(x_{i-1})}{x_i-x_{i-1}}\]</div>
<p>Therefore <span class="math">\(F(b)-F(a)=\sum_{i=1}^nf(c_i)(x_i-x_{i-1})\)</span> which is a Riemann sum of <span class="math">\(f\)</span> with respect to <span class="math">\(P\)</span>. The lower sum <span class="math">\(L(P,f)\)</span> and upper sum <span class="math">\(U(P,f)\)</span> of <span class="math">\(f\)</span> with respect to <span class="math">\(P\)</span> are defined as</p>
<div class="math">
\[\begin{split}L(P,f)=\sum_{i=1}^nf(p_i)(x_i-x_{i-1}),f(p_i)=\inf\lbrace f(x):x\in[x_{i-1},x_i]\rbrace\\
U(P,f)=\sum_{i=1}^nf(q_i)(x_i-x_{i-1}),f(q_i)=\sup\lbrace f(x):x\in[x_{i-1},x_i]\rbrace\end{split}\]</div>
<p>Therefore <span class="math">\(L(P,f)\leq F(b)-F(a)\leq U(P,f)\)</span>. Since <span class="math">\(P\)</span> was chosen arbitrarily, <span class="math">\(F(b)-F(a)\)</span> is an upper bound for the set of all lower sums of <span class="math">\(f\)</span> and a lower bound for the set of all upper sums of <span class="math">\(f\)</span> on the interval <span class="math">\([a,b]\)</span>. Since <span class="math">\(\int_a^b f(x)dx\)</span> exists, by definition the upper and lower integrals of <span class="math">\(f\)</span> on <span class="math">\([a,b]\)</span> must be both equal to <span class="math">\(\int_a^b f(x)dx\)</span>. The upper integral <span class="math">\(U(f)\)</span> is the greatest lower bound of the set of all upper sums of <span class="math">\(f\)</span> and the lower integral <span class="math">\(L(f)\)</span> is the least upper bound of the set of all lower sums of <span class="math">\(f\)</span>.</p>
<div class="math">
\[\begin{split}L(f)=\sup\lbrace L(P,f):P\text{ partitions }[a,b]\rbrace\\
U(f)=\inf\lbrace U(P,f):P\text{ partitions }[a,b]\rbrace\end{split}\]</div>
<p>From the above definitions it follows that</p>
<div class="math">
\[L(f)\leq F(b)-F(a)\leq U(f)\Rightarrow \boxed{F(b)-F(a)=\int_a^b f(x)dx}\]</div>
<p>According to the fundamental theorem of calculus if <span class="math">\(g:[a,b]\to\mathbb{R}\)</span> is integrable on <span class="math">\([a,b]\)</span>, and <span class="math">\(G(x)=\displaystyle\int_a^xg(t)dt\)</span> for any <span class="math">\(x\in[a,b]\)</span>, then <span class="math">\(G(x)\)</span> is continuous on <span class="math">\([a,b]\)</span>. Also, if <span class="math">\(g\)</span> is continuous at some <span class="math">\(c\in[a,b]\)</span> then <span class="math">\(G'(c)=g(c)\)</span>. First of all, since <span class="math">\(g\)</span> is integrable, it is also bounded by some <span class="math">\(M\in\mathbb{R}\)</span>. Let <span class="math">\(x,y\in[a,b]\)</span> and <span class="math">\(x\neq y\)</span>. Consider <span class="math">\(|G(x)-G(y)|=|\int_x^yg(t)dt|\leq M|x-y|\Rightarrow \displaystyle\frac{|G(x)-G(y)|}{|x-y|}\leq M\)</span> which proves that <span class="math">\(G\)</span> is Lipschitz and therefore continuous on <span class="math">\([a,b]\)</span>.</p>
<p>Suppose that <span class="math">\(g\)</span> is continuous at some <span class="math">\(c\in [a,b]\)</span>. Then for every <span class="math">\(\varepsilon &gt;0\)</span> there exists <span class="math">\(\delta &gt;0\)</span> such that if <span class="math">\(|x-c|&lt;\delta\)</span> then <span class="math">\(|g(x)-g(c)|&lt;\varepsilon\)</span>. Choose <span class="math">\(\varepsilon, x\)</span> such that <span class="math">\(|x-c|&lt;\delta\)</span>. Consider <span class="math">\(\displaystyle\Big|\frac{G(x)-G(c)}{x-c}-g(c)\Big|=\Big|\frac{1}{x-c}\int_c^x g(t)dt-g(c)\Big|=\Big|\frac{1}{x-c}\int_c^x[g(t)-g(c)]dt\Big|\)</span>. Since <span class="math">\(|t-c|&lt;\delta\)</span>, <span class="math">\(|g(t)-g(c)|&lt;\varepsilon\)</span>.</p>
<div class="math">
\[\begin{split}\Rightarrow \Big| \frac{G(x)-G(c)}{x-c}-g(c) \Big|&lt;\frac{1}{|x-c|}\varepsilon |x-c|=\varepsilon\end{split}\]</div>
<div class="math">
\[\therefore \lim_{x\to c}\frac{G(x)-G(c)}{x-c}=G'(c)=g(c)\]</div>
<p>It can also be proven that a function which is Lipschitz on an interval, is also uniformly continuous and therefore continuous on this interval. Assume that <span class="math">\(G\)</span> is Lipschitz but not uniformly continuous on <span class="math">\([a,b]\)</span>. Then, there exists <span class="math">\(\varepsilon &gt;0\)</span> such that for all <span class="math">\(n\in\mathbb{N}\)</span> there exist <span class="math">\(x_n,y_n\in[a,b]\)</span> with <span class="math">\(|x_n-y_n|&lt;1/n\)</span> and <span class="math">\(|G(x_n)-G(y_n)|\geq \varepsilon\)</span>. Since <span class="math">\(G\)</span> is Lipschitz, there exists <span class="math">\(M\in\mathbb{R}\)</span> such that <span class="math">\(\displaystyle|\frac{G(x_n)-G(y_n)}{x_n-y_n}|\leq M\)</span> for all <span class="math">\(n\)</span>. It follows that for large enough <span class="math">\(n\)</span>:</p>
<div class="math">
\[\begin{split}|G(x_n)-G(y_n)|\leq M|x_n-y_n|&lt;\frac{M}{n}&lt;\varepsilon\end{split}\]</div>
<p>But our assumption was that <span class="math">\(|G(x_n)-G(y_n)|\geq \varepsilon\)</span> for all <span class="math">\(n\)</span>. This contradiction proves that on some interval <span class="math">\([a,b]\)</span> if a function is Lipschitz then it is uniformly continuous.</p>
</div>
<div class="section" id="differentiation-rules">
<h2>Differentiation Rules<a class="headerlink" href="#differentiation-rules" title="Permalink to this headline">¶</a></h2>
<p>While proving <a class="reference internal" href="#taylor-s-theorem">Taylor&#8217;s theorem</a> we made use of <a class="reference internal" href="#the-product-rule">the product rule</a> and <a class="reference internal" href="#the-chain-rule">the chain rule</a> of differentiation.</p>
<div class="section" id="the-product-rule">
<h3>The Product Rule<a class="headerlink" href="#the-product-rule" title="Permalink to this headline">¶</a></h3>
<p>The product rule was utilized while taking the derivative of <span class="math">\(\displaystyle\frac{f^{(k)}(x)}{k!}(b-x)^k\)</span> with respect to x. Let <span class="math">\(G(x)=f(x)g(x)\)</span> where f&#8217; and g&#8217; both exist at some x=a. Then the derivative of <span class="math">\(G(x)\)</span> at x=a can be expressed as follows [<a class="reference internal" href="#id1">1</a>]:</p>
<div class="math">
\[\begin{split}G'(a)&amp;=\lim_{x\to a} \frac{G(x)-G(a)}{x-a}\\
&amp;=\lim_{x\to a}\frac{f(x)g(x)-f(a)g(x)+f(a)g(x)-f(a)g(a)}{x-a}\\
&amp;=\lim_{x\to a}\frac{f(x)-f(a)}{x-a}g(x)+\frac{g(x)-g(a)}{x-a}f(a)\\
&amp;=f'(a)g(a) +g'(a)f(a)\end{split}\]</div>
<p>This gives us <strong>the product rule</strong> of differentiation. The existence of f&#8217;(a) and g&#8217;(a) imply the continuity of f and g at x=a which is used in the last step of the above proof in order to obtain <span class="math">\(\displaystyle\lim_{x\to a}g(x)=g(a)\)</span> and <span class="math">\(\displaystyle\lim_{x\to a}f(x)=f(a)\)</span>. This can be shown using the definition of the derivative as follows:</p>
<div class="math">
\[f(x)-f(a)=\frac{f(x)-f(a)}{x-a}(x-a)\Rightarrow f(x)=f(a)+\frac{f(x)-f(a)}{x-a}(x-a)\]</div>
<div class="math">
\[\begin{split}\Rightarrow \lim_{x\to a}f(x)&amp;=\lim_{x\to a} f(a)+\lim_{x\to a}\frac{f(x)-f(a)}{x-a}(x-a)\\
&amp;=f(a)+\lim_{x\to a}\frac{f(x)-f(a)}{x-a}\lim_{x\to a}(x-a)\\
&amp;=f(a)+f'(a)\cdot 0=f(a)\end{split}\]</div>
<p>While proving the continuity of a function at a point where it is differentiable, we used <strong>the product rule of the limit operator</strong> which says that if f and g are two functions such that <span class="math">\(\displaystyle\lim_{x\to x_0}f(x)=F\)</span> and <span class="math">\(\displaystyle\lim_{x\to x_0}g(x)=G\)</span> then <span class="math">\(\displaystyle\lim_{x\to x_0}f(x)g(x)=FG\)</span>. The proof of that statement is as follows [<a class="reference internal" href="#id3">3</a>]: Since the limits exist, we know that for any <span class="math">\(\varepsilon&gt;0\)</span>, there exist <span class="math">\(\delta_f\)</span>, <span class="math">\(\delta_g\)</span> such that whenever <span class="math">\(|x-x_0|&lt;\delta_f\)</span>, <span class="math">\(|f(x)-F|&lt;\displaystyle\frac{\varepsilon}{2(1+|G|)}\)</span> and whenever <span class="math">\(|x-x_0|&lt;\delta_g\)</span>, <span class="math">\(|g(x)-G|&lt;\displaystyle\frac{\varepsilon}{2(1+|F|)}\)</span>. Also for <span class="math">\(\varepsilon=1\)</span> we know that there exists <span class="math">\(\delta_1\)</span> such that whenever <span class="math">\(|x-x_0|&lt;\delta_1\)</span>, <span class="math">\(|g(x)-G|&lt;1\)</span>. Suppose that <span class="math">\(\varepsilon &gt;0\)</span> and <span class="math">\(\delta=\min \lbrace\delta_f,\delta_g,\delta_1\rbrace\)</span>. If <span class="math">\(|x-x_0|&lt;\delta\)</span>, then we obtain:</p>
<div class="math">
\[\begin{split}|f(x)g(x)-FG|&amp;=|f(x)g(x)-Fg(x)+Fg(x)-FG|= |g(x)(f(x)-F)+F(g(x)-G)|\\
&amp;\leq |g(x)(f(x)-F)|+|F(g(x)-G)|=|g(x)|\cdot |f(x)-F|+|F|\cdot |g(x)-G|\\
&amp;&lt;|g(x)|\frac{\varepsilon}{2(1+|G|)}+(1+|F|)\frac{\varepsilon}{2(1+|F|)}\end{split}\]</div>
<p>At this point we need to show that <span class="math">\(|g(x)|&lt;(1+|G|)\)</span>:</p>
<div class="math">
\[\begin{split}|g(x)|=|g(x)-G+G|\leq |g(x)-G|+|G| &lt; 1+|G|\end{split}\]</div>
<p>Therefore</p>
<div class="math">
\[\begin{split}|f(x)g(x)-FG|&lt;(1+|G|)\frac{\varepsilon}{2(1+|G|)}+(1+|F|)\frac{\varepsilon}{2(1+|F|)}=\frac{\varepsilon}{2}+\frac{\varepsilon}{2}=\varepsilon\end{split}\]</div>
</div>
<div class="section" id="the-chain-rule">
<h3>The Chain Rule<a class="headerlink" href="#the-chain-rule" title="Permalink to this headline">¶</a></h3>
<p><strong>The chain rule</strong> of differentiation is applied in order to take the derivative of compound functions in form of <span class="math">\(f(g(x))\)</span> or <span class="math">\(f\circ g(x)\)</span> with respect to <span class="math">\(x\)</span>. If we equate <span class="math">\(g(x)\)</span> to a variable <span class="math">\(u\)</span>, then <span class="math">\(f'(g(x))\)</span> is computed as <span class="math">\(f'(u)g'(x)\)</span>. In order to prove this formula we can use the definition of derivative as follows [<a class="reference internal" href="#id4">4</a>]: Let <span class="math">\(y=f(u)\)</span>, <span class="math">\(y_0=f(u_0)\)</span>, <span class="math">\(u_0=g(x_0)\)</span>, then</p>
<div class="math">
\[\frac{dy}{dx}\Big \rvert_{x=x_0}=\lim_{x\to x_0}\frac{y-y_0}{x-x_0}=\lim_{x\to x_0}\frac{y-y_0}{u-u_0}\frac{u-u_0}{x-x_0}\]</div>
<p>Using <a class="reference internal" href="#taylor-s-theorem">Taylor&#8217;s theorem</a>, at any value of <span class="math">\(x\)</span> and <span class="math">\(u\)</span>, <span class="math">\(f(u)\)</span> and <span class="math">\(g(x)\)</span> can be expressed as follows:</p>
<div class="math">
\[\begin{split}&amp;f(u)=f(u_0)+f'(u_0)(u-u_0)+ ... +\frac{f^{(n)}(\xi)}{n!}(u-u_0)^n,\qquad  \xi\in(u_0,u)\\
&amp;f(u)-f(u_0)=f'(u_0)(u-u_0)+\varepsilon_1(u-u_0)\\
&amp;\Rightarrow\frac{f(u)-f(u_0)}{u-u_0}(u-u_0)=(f'(u_0)+\varepsilon_1)(u-u_0)\end{split}\]</div>
<div class="math">
\[\begin{split}&amp;g(x)=g(x_0)+g'(x_0)(x-x_0)+ ... + \frac{g^{(n)}(c)}{n!}(x-x_0)^n,\qquad  c\in(x_0,x)\\
&amp;g(x)-g(x_0)=g'(x_0)(x-x_0)+\varepsilon_2(x-x_0)\\
&amp;\Rightarrow\frac{g(x)-g(x_0)}{x-x_0}(x-x_0)=(g'(x_0)+\varepsilon_2)(x-x_0)\end{split}\]</div>
<p>In the above expressions, after the first derivative of f and g, the remaining parts of the Taylor expansions are summarized as <span class="math">\(\varepsilon_1(u-u_0)\)</span> and <span class="math">\(\varepsilon_2(x-x_0)\)</span> respectively. Using the Taylor expansions it can be shown that <span class="math">\(\varepsilon_1\)</span> and <span class="math">\(\varepsilon_2\)</span> both converge to zero as <span class="math">\(x\)</span> converges to <span class="math">\(x_0\)</span>:</p>
<div class="math">
\[\lim_{x\to x_0}\frac{g(x)-g(x_0)}{x-x_0}-g'(x_0)=\lim_{x\to x_0}\varepsilon_2=0\]</div>
<div class="math">
\[\lim_{x\to x_0}u-u_0=\lim_{x\to x_0}g(x)-g(x_0)=\lim_{x\to x_0}(g'(x_0)+\varepsilon_2)(x-x_0)=0\]</div>
<div class="math">
\[\lim_{x\to x_0}\frac{f(u)-f(u_0)}{u-u_0}-f'(u_0)=\lim_{u\to u_0}\frac{f(u)-f(u_0)}{u-u_0}-f'(u_0)=\lim_{u\to u_0}\varepsilon_1=0\]</div>
<p>Using this result the derivative of f(g(x)) with respect to x is computed as follows:</p>
<div class="math">
\[\begin{split}y-y_0&amp;=(f'(u_0)+\varepsilon_1)(u-u_0)\\
&amp;=(f'(u_0)+\varepsilon_1)(g'(x_0)+\varepsilon_2)(x-x_0)\end{split}\]</div>
<div class="math">
\[\begin{split}\lim_{x\to x_0}\frac{y-y_0}{x-x_0}&amp;=\lim_{x\to x_0}\Big[f'(u_0)\cdot g'(x_0)+\varepsilon_1\cdot g'(x_0)+\varepsilon_2\cdot f'(u_0)+\varepsilon_1 \cdot \varepsilon_2\Big]\\
&amp;=f'(u_0)\cdot g'(x_0)=f'(g(x_0))\cdot g'(x_0)\end{split}\]</div>
<p>Another differentiation rule that we used while proving <a class="reference internal" href="#taylor-s-theorem">Taylor&#8217;s theorem</a> is the rule to calculate the <strong>derivative of a power</strong>. According to this rule, if a function has the form <span class="math">\(f(x)=x^n\)</span>, then its derivative with respect to <span class="math">\(x\)</span> is <span class="math">\(nx^{n-1}\)</span>. There are to ways to prove this formula. The first one uses the <a class="reference internal" href="#binomial-theorem">binomial theorem</a> . The derivative of <span class="math">\(f\)</span> at some <span class="math">\(x=x_0\)</span> is computed as <span class="math">\(\displaystyle\lim_{h\to 0}\displaystyle\frac{f(x_0+h)-f(x_0)}{h}\)</span>. Using the binomial expansion of <span class="math">\(f(x_0+h)\)</span> we obtain</p>
<div class="math">
\[\begin{split}f'(x_0)&amp;=\lim_{h\to 0}\frac{(x_0+h)^n-{x_0}^n}{h}\\
&amp;=\lim_{h\to 0}\frac{\binom{n}{0}{x_0}^n+\binom{n}{1}{x_0}^{n-1}h+...+\binom{n}{n-1}x_0h^{n-1}+\binom{n}{n}h^n-{x_0}^n}{h}\\
&amp;=n{x_0}^{n-1}+\lim_{h\to 0}h\Bigg(\binom{n}{2}{x_0}^{n-2}+\binom{n}{3}{x_0}^{n-3}h+\quad ...\quad+\binom{n}{n-1}x_0h^{n-2}+\binom{n}{n}h^{n-1}\Bigg)\\
&amp;=\boxed{n{x_0}^{n-1}}\end{split}\]</div>
<p>The second way to prove the formula for the derivative of a power uses the following expansion</p>
<div class="math">
\[x^n-{x_0}^n=(x-x_0)(x^{n-1}+x_0x^{n-2}+{x_0}^2x^{n-3}+{x_0}^3x^{n-4}+\quad ...\quad +{x_0}^{n-2}x+{x_0}^{n-1})\]</div>
<p>The derivative of <span class="math">\(f\)</span> at some <span class="math">\(x=x_0\)</span> can also be computed as <span class="math">\(\displaystyle\lim_{x\to x_0}\displaystyle\frac{f(x)-f(x_0)}{x-x_0}\)</span>. Using the above expansion we obtain:</p>
<div class="math">
\[\begin{split}f'(x_0)&amp;=\lim_{x\to x_0}\frac{f(x)-f(x_0)}{x-x_0}=\lim_{x\to x_0}\frac{x^n-{x_0}^n}{x-x_0}\\
&amp;=\lim_{x\to x_0}(x^{n-1}+x_0x^{n-2}+{x_0}^2x^{n-3}+{x_0}^3x^{n-4}+ \quad ... \quad +{x_0}^{n-2}x+{x_0}^{n-1})\\
&amp;=({x_0}^{n-1}+x_0{x_0}^{n-2}+{x_0}^2{x_0}^{n-3}+...+{x_0}^{n-2}x_0+{x_0}^{n-1})\\
&amp;=\boxed{n{x_0}^{n-1}}\end{split}\]</div>
<p>The expansion used in the above proof can be obtained using the finite geometric series summation formula. This formula states that:</p>
<div class="math">
\[\sum_{k=0}^{n-1}r^k=\frac{1-r^n}{1-r},\quad r\neq 1\]</div>
<p>In the above formula let <span class="math">\(r=x_0/x\)</span>. If <span class="math">\(x=x_0\)</span> then <span class="math">\(x^n-{x_0}^n=0\)</span> and there is no need for an expansion formula. Suppose <span class="math">\(x\neq x_0\)</span>. Then <span class="math">\(\displaystyle\sum_{k=0}^{n-1}\Big(\frac{x_0}{x}\Big)^k=\displaystyle\frac{1-\Big(\displaystyle\frac{x_0}{x}\Big)^n}{1-\displaystyle\frac{x_0}{x}}\)</span>. Using this result we can write <span class="math">\(x^n-{x_0}^n\)</span> in the following form:</p>
<div class="math">
\[\begin{split}x^n-{x_0}^n&amp;=x^n\Big(1-(\frac{x_0}{x})^n\Big)=x^n\Big(1-\frac{x_0}{x}\Big)\sum_{k=0}^{n-1}(\frac{x_0}{x})^k\\
&amp;=x\Big(1-\frac{x_0}{x}\Big)x^{n-1}\Big(1+\frac{x_0}{x}+(\frac{x_0}{x})^2+...+(\frac{x_0}{x})^{n-2}+(\frac{x_0}{x})^{n-1}\Big)\\
&amp;=(x-x_0)(x^{n-1}+x_0x^{n-2}+{x_0}^2x^{n-3}+...+{x_0}^{n-2}x+{x_0}^{n-1})\end{split}\]</div>
</div>
</div>
<div class="section" id="binomial-theorem">
<h2>Binomial theorem<a class="headerlink" href="#binomial-theorem" title="Permalink to this headline">¶</a></h2>
<p>Binomial theorem states that for any <span class="math">\(a,b\in\mathbb{R}\)</span> and <span class="math">\(n\in\mathbb{N}\)</span>, [<a class="reference internal" href="#id1">1</a>]</p>
<div class="math">
\[\begin{split}(a+b)^n&amp;=\binom{n}{0}a^n+\binom{n}{1}a^{n-1}b+\binom{n}{2}a^{n-2}b^2+\quad ...\quad \\
&amp;+\binom{n}{n-2}a^2b^{n-2}+\binom{n}{n-1}ab^{n-1}+\binom{n}{n}b^n\end{split}\]</div>
<p>This can be inductively proven with the help of Pascal&#8217;s triangle theorem which states that</p>
<div class="math">
\[\binom{n}{k-1}+\binom{n}{k}=\binom{n+1}{k}\]</div>
<p>Pascal&#8217;s triangle theorem can be proven by inserting the definition of the binomial coefficient <span class="math">\(\binom{n}{k}\)</span> in the above equation:</p>
<div class="math">
\[\begin{split}&amp;\frac{n!}{(k-1)!(n-k+1)!}+\frac{n!}{k!(n-k)!}=\frac{n!}{(n-k)!(k-1)!}\Big[\frac{1}{n-k+1}+\frac{1}{k}\Big]\\
&amp;=\frac{n!}{(n-k)!(k-1)!}\Big[\frac{n+1}{k(n-k+1)}\Big]=\frac{(n+1)!}{k!(n+1-k)!}=\binom{n+1}{k}\end{split}\]</div>
<p>For <span class="math">\(n=1\)</span>, <span class="math">\(\displaystyle\sum_{k=0}^1\displaystyle\binom{1}{k}a^{1-k}b^k=\displaystyle\binom{1}{0}a+\displaystyle\binom{1}{1}b=(a+b)^1\)</span> and the binomial formula for <span class="math">\((a+b)^n\)</span> is true. Suppose the formula is also true for some <span class="math">\(n\in\mathbb{N}\)</span>. Then</p>
<div class="math">
\[\begin{split}(a+b)^{n+1}&amp;=(a+b)(a+b)^n=(a+b)\sum_{k=0}^n\binom{n}{k}a^{n-k}b^k\\
&amp;=\Big[\binom{n+1}{0}a^{n+1}+\binom{n}{1}a^nb+\binom{n}{2}a^{n-1}b^2+\binom{n}{3}a^{n-2}b^3+... \\
&amp;+\binom{n}{n-3}a^4b^{n-3}+\binom{n}{n-2}a^3b^{n-2}+\binom{n}{n-1}a^2b^{n-1}+\binom{n}{n}ab^n\Big]\\
&amp;+\Big[\binom{n}{0}a^nb+\binom{n}{1}a^{n-1}b^2+\binom{n}{2}a^{n-2}b^3+\binom{n}{3}a^{n-3}b^4 + ... \\
&amp;+ \binom{n}{n-3}a^3b^{n-2}+\binom{n}{n-2}a^2b^{n-1}+\binom{n}{n-1}ab^n+\binom{n+1}{n+1}b^{n+1}\Big]\\
&amp;=\binom{n+1}{0}a^{n+1}+a^nb\Big[\binom{n}{1}+\binom{n}{0}\Big]+a^{n-1}b^2\Big[\binom{n}{1}+\binom{n}{2}\Big]\\
&amp;+a^{n-2}b^3\Big[\binom{n}{3}+\binom{n}{2}\Big]+...+a^3b^{n-2}\Big[\binom{n}{n-2}+\binom{n}{n-3}\Big]\\
&amp;+a^2b^{n-1}\Big[\binom{n}{n-1}+\binom{n}{n-2}\Big]+ab^n\Big[\binom{n}{n}+\binom{n}{n-1}\Big]+\binom{n+1}{n+1}b^{n+1}\\
&amp;=\binom{n+1}{0}a^{n+1}+\binom{n+1}{1}a^nb+\binom{n+1}{2}a^{n-1}b^2+\binom{n+1}{3}a^{n-2}b^3 +... \\
&amp;+\binom{n+1}{n-2}a^3b^{n-2}+\binom{n+1}{n-1}a^2b^{n-1}+\binom{n+1}{n}ab^n+\binom{n+1}{n+1}b^{n+1}\\
&amp;=\sum_{k=0}^{n+1}\binom{n+1}{k}a^{n+1-k}b^k\end{split}\]</div>
<p>which shows that the formula is also true for <span class="math">\(n+1\)</span> if it is true for <span class="math">\(n\)</span>. This completes the proof of the binomial theorem.</p>
<p>The binomial theorem is also one of the reasons why <span class="math">\(0^0\)</span> was defined as equal to <span class="math">\(1\)</span> by mathematicians. Consider the following expansion [<a class="reference internal" href="#id5">5</a>]:</p>
<div class="math">
\[\begin{split}(0+x)^n&amp;=\binom{n}{0}0^nx^0+\binom{n}{1}0^{n-1}x+...+\binom{n}{n-1}0^1x^{n-1}+\binom{n}{n}0^0x^n\\
          &amp;=x^n\end{split}\]</div>
<p>If <span class="math">\(0^0\)</span> were undefined or defined as zero, then the binominal theorem would yield <span class="math">\(x^n=0^0x^n=0\)</span> or <span class="math">\(x^n=\)</span> undefined.</p>
</div>
<div class="section" id="weierstrass-maximum-minimum-theorem">
<h2>Weierstrass maximum minimum theorem<a class="headerlink" href="#weierstrass-maximum-minimum-theorem" title="Permalink to this headline">¶</a></h2>
<p>While proving Rolle&#8217;s theorem we made use of <strong>Weierstrass&#8217; maximum-minimum theorem</strong> which states that if a function is continuous on a closed interval <span class="math">\([a,b]\)</span>, then this function has a maximum and a minimum value on <span class="math">\([a,b]\)</span>. We can start the proof of Weierstrass&#8217; maximum-minimum theorem by showing that the continuity of <span class="math">\(f:[a,b]\to\mathbb{R}\)</span> on <span class="math">\([a,b]\)</span> implies its boundedness on <span class="math">\([a,b]\)</span>. This can be proven by contradiction. Assume that <span class="math">\(f:[a,b]\to\mathbb{R}\)</span> is continuous but not bounded. Then for any <span class="math">\(n\in\mathbb{N}\)</span> there must be <span class="math">\(x_n\in [a,b]\)</span> such that <span class="math">\(\lvert f(x_n)\lvert &gt; n\)</span>. Obviously, <span class="math">\(\lbrace x_n \rbrace\)</span> is a sequence bounded by a and b. From the boundedness of <span class="math">\(\lbrace x_n \rbrace\)</span> it follows that <span class="math">\(\lbrace x_n \rbrace\)</span> has a convergent subsequence <span class="math">\(\lbrace x_{n_k} \rbrace\)</span> such that <span class="math">\(x_{n_k}\to c\in [a,b]\)</span>. Since <span class="math">\(f\)</span> is a continuous function, <span class="math">\(f(x_{n_k})\to f(c)\)</span>. This means that for any real number <span class="math">\(\varepsilon &gt; 0\)</span>, there exists <span class="math">\(k_0\in\mathbb{N}\)</span> such that if <span class="math">\(\lvert x_{n_k}-c \rvert &lt; 1/n_{k_0}\)</span> then <span class="math">\(\lvert f(x_{n_k})-f(c)\rvert &lt; \varepsilon\)</span> and <span class="math">\(\lvert f(x_{n_k})\rvert &lt; \varepsilon + \lvert f(c) \rvert\)</span>. Since <span class="math">\(\lbrace x_{n_k} \rbrace\)</span> converges to <span class="math">\(c\)</span>, it is possible to choose k large enough so that <span class="math">\(\lvert x_{n_k}-c \rvert &lt;1/n_{k_0}\)</span> and <span class="math">\(\varepsilon+\lvert f(c) \rvert &lt; n_k\)</span>. But in this case we obtain <span class="math">\(\lvert f(x_{n_k} \rvert &lt; n_k\)</span> which is in contradiction with our initial assumption that <span class="math">\(\lvert f(x_n)\rvert &gt;n\)</span> for any <span class="math">\(n\in\mathbb{N}\)</span>. This proves the boundedness of <span class="math">\(f:[a,b]\to\mathbb{R}\)</span>. As a result, <span class="math">\(f\)</span> has a supremum <span class="math">\(S\)</span> on <span class="math">\([a,b]\)</span>. Using the definition of supremum, we know that for every <span class="math">\(n\in\mathbb{N}\)</span> there exists <span class="math">\(x_n \in [a,b]\)</span> such that <span class="math">\(S-1/n &lt; f(x_n) \leq S\)</span> from which <span class="math">\(f(x_n)\to S\)</span> follows. This gives us another bounded sequence <span class="math">\(\lbrace x_n \rbrace\)</span> with a convergent subsequence <span class="math">\(x_{n_k}\to c\)</span> in <span class="math">\([a,b]\)</span> and <span class="math">\(f(x _{n_k})\to f(c)\)</span>. Since <span class="math">\(f(x _{n_k})\)</span> is a subsequence of <span class="math">\(f(x_n)\)</span>, these two sequences have to converge to the same limit such that <span class="math">\(f(c)=S\)</span>. Since <span class="math">\(c\in[a,b]\)</span> and <span class="math">\(\forall x\in[a,b]\)</span>, <span class="math">\(f(x)\leq f(c)\)</span>, this completes the proof of the maximum part of the Weierstrass&#8217; maximum-minimum theorem. The minimum part can be proven in the same way.</p>
<p>Combining <a class="reference internal" href="#weierstrass-maximum-minimum-theorem">Weierstrass maximum minimum theorem</a> with the integrability of a continuous function we obtain the mean value theorem for integrals</p>
<div class="section" id="mean-value-theorem-for-integrals">
<h3>Mean Value Theorem for Integrals<a class="headerlink" href="#mean-value-theorem-for-integrals" title="Permalink to this headline">¶</a></h3>
<p>Let <span class="math">\(f\)</span> be continuous on <span class="math">\([a,b]\)</span>. Then <span class="math">\(\exists p,q\in[a,b]:f(p)=\inf{f(x):x\in[a,b]},f(q)=\sup{f(x):x\in[a,b]}\)</span>.It follows that</p>
<div class="math">
\[f(p)(b-a)\leq\int_a^bf\leq f(q)(b-a)\]</div>
<div class="math">
\[\Rightarrow f(p)\leq \frac{1}{b-a}\int_a^bf\leq f(q)\]</div>
<p>Therefore according to <a class="reference internal" href="#bolzano-intermediate-value-theorem">Bolzano intermediate value theorem</a> <span class="math">\(\exists c\in[a,b]:f(c)=\frac{1}{b-a}\int_a^bf\Rightarrow \int_a^bf=f(c)(b-a)\)</span>.</p>
</div>
<div class="section" id="bolzano-intermediate-value-theorem">
<h3>Bolzano intermediate value theorem<a class="headerlink" href="#bolzano-intermediate-value-theorem" title="Permalink to this headline">¶</a></h3>
<p>This theorem states that if <span class="math">\(f\)</span> is continuous on <span class="math">\([a,b]\)</span> and <span class="math">\(f(a)&lt;0&lt;f(b)\)</span> then <span class="math">\(\exists c\in(a,b):f(c)=0\)</span>.</p>
<p>Consider <span class="math">\(\displaystyle f\Bigg(\frac{a+b}{2}\Bigg)\)</span>. If <span class="math">\(\displaystyle f\Bigg(\frac{a+b}{2}\Bigg)=0\)</span> then we found <span class="math">\(c\)</span>. Otherwise, if <span class="math">\(\displaystyle f\Bigg(\frac{a+b}{2}\Bigg)&lt;0\)</span> let <span class="math">\(a_1=(a+b)/2, b_1=b\)</span> and consider <span class="math">\(\displaystyle f\Bigg(\frac{a_1+b_1}{2}\Bigg)\)</span>. If <span class="math">\(\displaystyle f\Bigg(\frac{a_1+b_1}{2}\Bigg)=0\)</span> then we found <span class="math">\(c\)</span>. Otherwise, if <span class="math">\(\displaystyle f\Bigg(\frac{a_1+b_1}{2}\Bigg)&gt;0\)</span> let <span class="math">\(b_2=(a_1+b_1)/2, a_2=a_1\)</span> and consider <span class="math">\(\displaystyle f\Bigg(\frac{a_2+b_2}{2}\Bigg)\)</span>. Continuing this way we either find <span class="math">\(c\)</span> after a finite number of updates or we get a monotone increasing sequence <span class="math">\(\lbrace a_n\rbrace\)</span> and a monotone decreasing sequence <span class="math">\(\lbrace b_n\rbrace\)</span>. Since these sequences are also bounded, they are both convergent. Also, because <span class="math">\(b_n=a_n+\displaystyle\frac{b-a}{2^n}\)</span>, they converge to the same limit <span class="math">\(c\in[a,b]\)</span>. Due to the continuity of <span class="math">\(f\)</span> on <span class="math">\([a,b]\)</span> it follows that <span class="math">\(f(a_n)\to f(c),f(b_n)\to f(c)\)</span>. Furthermore <span class="math">\(\forall n,f(a_n)&lt;0, f(b_n)&gt;0\)</span> which implies that <span class="math">\(0\leq f(c)\leq 0\Rightarrow \boxed{f(c)=0}\)</span>.</p>
<p>In the proof of the Weierstrass&#8217; maximum-minimum theorem we made use of several facts without showing why they are true. The first one of these facts is that any bounded sequence has a convergent subsequence (<strong>Bolzano-Weierstrass theorem</strong>).</p>
</div>
</div>
<div class="section" id="every-bounded-sequence-has-a-convergent-subsequence-bolzano-weierstrass">
<h2>Every bounded sequence has a convergent subsequence (Bolzano-Weierstrass)<a class="headerlink" href="#every-bounded-sequence-has-a-convergent-subsequence-bolzano-weierstrass" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math">\(\lbrace x_n \rbrace\)</span> be any real valued sequence. We can call <span class="math">\(x_p\)</span> a peak value of <span class="math">\(\lbrace x_n\rbrace\)</span> if for all <span class="math">\(k\in\mathbb{N}\)</span>, <span class="math">\(x_{p+k}\leq x_p\)</span>. Then <span class="math">\(\lbrace x_n \rbrace\)</span> has either an infinite number of peak values or only a finite number of them. In case of infinitely many peak values, for any <span class="math">\(k\in\mathbb{N}\)</span>, There exists a peak value <span class="math">\(x_{n_k}\)</span> and these peak values build a decreasing monotone subsequence <span class="math">\(\lbrace x_{n_k} \rbrace\)</span>. In case of a finite number of peak values, let <span class="math">\(x_N\)</span> be the last of them and let <span class="math">\(n_1 &gt; N\)</span>. Then, <span class="math">\(x_{n_1}\)</span> is not a peak value and therefore there exists <span class="math">\(x_{n_2}\)</span> such that <span class="math">\(x_{n_1} \leq x_{n_2}\)</span>. Also, for any <span class="math">\(k\in\mathbb{N}\)</span>, there exist <span class="math">\(x_{n_k}\)</span> and <span class="math">\(x_{n_{k+1}}\)</span> such that <span class="math">\(n_k &gt;N\)</span> and <span class="math">\(x_{n_k} \leq x_{n_{k+1}}\)</span>. Therefore, a monotone increasing subsequence <span class="math">\(\lbrace x_{n_k} \rbrace\)</span> of <span class="math">\(\lbrace x_n \rbrace\)</span> can be built using these non-peak values with indices greater than <span class="math">\(N\)</span>. It follows that any real valued sequence has a monotone subsequence. It can also be shown that if a monotone sequence is bounded, then it is convergent. Now suppose that <span class="math">\(\lbrace x_n \rbrace\)</span> is a real-valued and bounded sequence and <span class="math">\(\lbrace x_{n_k} \rbrace\)</span> is its monotone increasing subsequence. Then <span class="math">\(\lbrace x_{n_k} \rbrace\)</span> is also bounded. Let <span class="math">\(S\)</span> be the supremum of <span class="math">\(\lbrace x_{n_k} \rbrace\)</span>. Then, for every <span class="math">\(\varepsilon &gt;0\)</span>, there exists <span class="math">\(K\in\mathbb{N}\)</span> such that <span class="math">\(S-\varepsilon &lt; x_{n_K} \leq S\)</span>. Since <span class="math">\(\lbrace x_{n_k} \rbrace\)</span> is an increasing sequence, <span class="math">\(\forall k&gt;K\)</span>, <span class="math">\(S-\varepsilon &lt; x_{n_K}\leq x_{n_k} \leq S\)</span> from which we can obtain by subtracting <span class="math">\(S\)</span> from both sides of the inequality the following relationship: <span class="math">\(\lvert x_{n_k}-S \rvert &lt;\varepsilon\)</span>. This completes the proof that the monotone subsequence of a bounded sequence is convergent and therefore every bounded sequence has a convergent subsequence.</p>
<p>The next fact that we used in the proof of Weierstrass&#8217; maximum-minimum theorem is that if a convergent sequence <span class="math">\(a_n \to L\)</span> is in <span class="math">\([A,B]\)</span> then its limit <span class="math">\(L\)</span> is also in <span class="math">\([A,B]\)</span>. We can start the proof of this fact by first proving that the limit of a non-negative convergent sequence <span class="math">\(a_n \to L\)</span> is also non-negative. Clearly, for any <span class="math">\(\varepsilon &gt; 0\)</span>, there exists <span class="math">\(N_{\varepsilon}\in\mathbb{N}\)</span> such that <span class="math">\(n&gt;N_{\varepsilon}\)</span> implies <span class="math">\(\lvert a_n - L \rvert &lt;\varepsilon\)</span>. If we assume a negative limit then we obtain <span class="math">\(a_n-L &lt;\varepsilon \Rightarrow a_n &lt;\varepsilon + L\)</span>. However we could choose <span class="math">\(\varepsilon\)</span> small enough such that <span class="math">\(\varepsilon &lt;\lvert L \rvert\)</span>. Then we would obtain <span class="math">\(a_n &lt;\varepsilon +L &lt;0\)</span> which is a contradiction. Therefore the limit of a non-negative convergent sequence must be non-negative. The next step in the proof is to observe the behaviours of the non-negative sequences <span class="math">\(\lbrace a_n-A \rbrace\)</span> and <span class="math">\(\lbrace B-a_n \rbrace\)</span>. Clearly, <span class="math">\(a_n-A \to L-A\geq 0\Rightarrow A \leq L\)</span> and <span class="math">\(B-a_n\to B-L \geq 0 \Rightarrow L\leq B\)</span>. It follows that <span class="math">\(L\in [A,B]\)</span>.</p>
<p>In the proof of Weierstrass&#8217; maximum-minimum theorem we also used the fact that a sequence is convergent with a limit if and only if each of its subsequences is convergent with the same limit. In order to prove this let <span class="math">\(x_n\to L\)</span>. Then for any <span class="math">\(\varepsilon &gt;0\)</span> there exists <span class="math">\(N_{\varepsilon}\)</span> such that <span class="math">\(n&gt;N_{\varepsilon}\)</span> implies <span class="math">\(\lvert x_n-L\rvert&lt;\varepsilon\)</span>. Then let <span class="math">\(\lbrace x_{n_k}\rbrace\)</span> be any subsequence of <span class="math">\(\lbrace x_n \rbrace\)</span>. For every <span class="math">\(k&gt;N_{\varepsilon}\)</span> we know that <span class="math">\(n_k\geq k&gt; N_{\varepsilon}\)</span> and <span class="math">\(\lvert x_{n_k}-L\rvert&lt;\varepsilon\)</span> and therefore <span class="math">\(x_{n_k}\to L\)</span>. Conversely, if any subsequence of <span class="math">\(\lbrace x_n \rbrace\)</span> converges to <span class="math">\(L\)</span>, then since <span class="math">\(\lbrace x_n\rbrace\)</span> is a subsequence of itself <span class="math">\(x_n\to L\)</span>.</p>
<div class="section" id="a-continuous-function-is-integrable">
<h3>A continuous function is integrable<a class="headerlink" href="#a-continuous-function-is-integrable" title="Permalink to this headline">¶</a></h3>
<p>Another place where Weierstress&#8217; maximum-minimum theorem can be used is in the proof of the integrability of a continuous function. While proving the Weierstrass&#8217; maximum-minimum theorem, we made use of the boundedness of a continuous function. A further implication of the continuity is that a function <span class="math">\(f\)</span> which is continuous on an interval <span class="math">\([a,b]\subset\mathbb{R}\)</span> is integrable on <span class="math">\([a,b]\)</span>. In order to prove this, we use the fact that <span class="math">\(f\)</span> is also uniformly continuous on <span class="math">\([a,b]\)</span>. Suppose <span class="math">\(\varepsilon &gt;0\)</span>, then <span class="math">\(\exists \delta &gt;0\)</span> such that for any <span class="math">\(x,y\)</span> with <span class="math">\(|x-y|&lt;\delta\)</span>, <span class="math">\(|f(x)-f(y)|&lt;\varepsilon / (b-a)\)</span>. We can choose a partition <span class="math">\(P=\lbrace x_0,x_1, ... , x_n\rbrace\)</span> of <span class="math">\([a,b]\)</span> such that for any <span class="math">\(i\in\lbrace 1,...,n\rbrace\)</span>, <span class="math">\(|x_i-x_{i-1}|&lt;\delta\)</span>. Since <span class="math">\(f\)</span> is continuous on every interval <span class="math">\([x_{i-1},x_i]\)</span>, according to Weierstrass&#8217; maximum-minimum theorem on each one of these intervals there exist <span class="math">\(p_i,q_i\in[x_{i-1},x_i]\)</span> such that <span class="math">\(f(p_i)=\inf\lbrace f(x):x\in[x_{i-1},x_i]\rbrace\)</span> and <span class="math">\(f(q_i)=\sup\lbrace f(x):x\in[x_{i-1},x_i]\rbrace\)</span>. Furthermore since <span class="math">\(|q_i-p_i|\)</span> is always less than <span class="math">\(\delta\)</span>, <span class="math">\(|f(q_i)-f(p_i)|\)</span> is always less than <span class="math">\(\varepsilon/(b-a)\)</span>. Now, <span class="math">\(U(P,f)-L(P,f)\)</span> can be computed as follows:</p>
<div class="math">
\[\begin{split}U(P,f)-L(P,f)&amp;=\sum_{i=1}^{n}(f(q_i)-f(p_i))(x_i-x_{i-1})\\
                         &amp;&lt;\frac{\varepsilon}{b-a}\sum_{i=1}^{n}(x_i-x_{i-1})\\
                         &amp;=\frac{\varepsilon}{b-a}(b-a)=\varepsilon\end{split}\]</div>
<p>Therefore, according to the <a class="reference internal" href="#cauchy-criterion-for-integrability">Cauchy criterion for integrability</a>, <span class="math">\(\int_a^bf(x)dx\)</span> exists. The definitions of <span class="math">\(U(P,f),L(P,f)\)</span> can be found in the section about <a class="reference internal" href="#the-fundamental-theorem-of-calculus">the fundamental theorem of calculus</a></p>
<p>In order to prove that if <span class="math">\(f\)</span> is continuous on <span class="math">\([a,b]\)</span> then it is uniformly continuous on <span class="math">\([a,b]\)</span> we can assume that <span class="math">\(\exists \varepsilon&gt;0 : \forall n \exists x_n,y_n\in[a,b]: |x_n-y_n|&lt;1/n \text{ and }|f(x_n)-f(y_n)|\geq\varepsilon\)</span>. Then <span class="math">\(\lbrace x_n \rbrace,\lbrace y_n \rbrace\)</span> have convergent subsequences <span class="math">\(\lbrace x_{n_k} \rbrace,\lbrace y_{n_k} \rbrace\)</span> with <span class="math">\(|x_{n_k}-y_{n_k}|&lt;1/n_k\forall k\)</span>. It follows that <span class="math">\(x_{n_k}\to c\in[a,b],y_{n_k}\to c\in[a,b]\Rightarrow f(x_{n_k})\to f(c),f(y_{n_k})\to f(c)\)</span>. Therefore for large enough <span class="math">\(k\)</span>, <span class="math">\(|f(x_{n_k})-f(y_{n_k})|&lt;\varepsilon\)</span>. This contradiction completes the proof.</p>
</div>
</div>
<div class="section" id="cauchy-criterion-for-integrability">
<h2>Cauchy criterion for integrability<a class="headerlink" href="#cauchy-criterion-for-integrability" title="Permalink to this headline">¶</a></h2>
<p>According to this criterion a function <span class="math">\(f\)</span> is integrable on an interval <span class="math">\([a,b]\)</span> if and only if for every <span class="math">\(\varepsilon &gt;0\)</span> there exists a partition <span class="math">\(P\)</span> of <span class="math">\([a,b]\)</span> such that <span class="math">\(U(P,f)-L(P,f)&lt;\varepsilon\)</span>.</p>
<p>If <span class="math">\(\int_a^b f=\alpha\)</span> then there exists a sequence of partitions <span class="math">\(\lbrace P_n \rbrace\)</span> such that <span class="math">\(U(P_n,f)\to\alpha\)</span> and <span class="math">\(L(P_n,f)\to alpha\)</span>. Then <span class="math">\(U(P_n,f)-L(P_n,f)\to 0\)</span> and for every <span class="math">\(\varepsilon&gt;0\)</span> for large enough <span class="math">\(n\)</span>, <span class="math">\(U(P_n,f)-L(P_n,f)&lt;\varepsilon\)</span>.</p>
<p>Conversely, if for every <span class="math">\(\varepsilon&gt;0\)</span> there exists <span class="math">\(P_{\varepsilon}\)</span> such that <span class="math">\(U(P_{\varepsilon},f)-L(P_{\varepsilon},f)&lt;\varepsilon\)</span> then <span class="math">\(0\leq U(f)-L(f)&lt;\varepsilon\)</span> for every positive <span class="math">\(\varepsilon\)</span> which implies that <span class="math">\(U(f)=L(f)=\int_a^b f\)</span>.</p>
<p>In the proof of the Cauchy integrability criterion we used the fact that if <span class="math">\(f\)</span> is integrable on <span class="math">\([a,b]\)</span> then there exists a sequence of partitions <span class="math">\(\lbrace P_n \rbrace\)</span> such that <span class="math">\(U(P_n,f)\to\alpha\)</span> and <span class="math">\(L(P_n,f)\to \alpha\)</span>.</p>
<p>If <span class="math">\(f\)</span> is integrable on <span class="math">\([a,b]\)</span> then <span class="math">\(U(f)=L(f)=\alpha\)</span> from which it follows that for every <span class="math">\(n\in\mathbb{N}\)</span>, there exist partitions of <span class="math">\([a,b]\)</span>, <span class="math">\(Q_n,R_n\)</span> and their union <span class="math">\(P_n=Q_n\cup R_n\)</span> such that</p>
<div class="math">
\[\begin{split}\alpha-\frac{1}{n}&lt;L(Q_n,f)\leq L(P_n,f)\leq U(P_n,f)\leq U(R_n,f)&lt;\alpha+\frac{1}{n}\end{split}\]</div>
<div class="math">
\[\begin{split}\Rightarrow |L(P_n,f)-\alpha|&lt;\frac{1}{n},\quad |U(P_n,f)-\alpha|&lt;\frac{1}{n} \Rightarrow L(P_n,f)\to\alpha,  U(P_n,f)\to\alpha\end{split}\]</div>
<p>Conversely, if there exists a sequence of partitions <span class="math">\(\lbrace P_n \rbrace\)</span> such that <span class="math">\(U(P_n,f)\to\alpha\)</span> and <span class="math">\(L(P_n,f)\to \alpha\)</span>, then</p>
<div class="math">
\[\alpha\leq L(f)\leq U(f)\leq\alpha\Rightarrow L(f)=U(f)=\alpha=\int_a^bf`\]</div>
<p>Assume that <span class="math">\(L(P_n,f)\to\alpha\)</span> and <span class="math">\(L(f)&lt;\alpha\)</span>. Then for large enough <span class="math">\(n\)</span>, <span class="math">\(|L(P_n,f)-\alpha|&lt;\alpha-L(f)\)</span>. It follows that <span class="math">\(L(f)-\alpha &lt;L(P_n,f)-\alpha\)</span> and <span class="math">\(L(P_n,f)\)</span> is greater than the least upper bound of lower sums of <span class="math">\(f\)</span> which is a contradiction. <span class="math">\(U(f)\leq \alpha\)</span> can be proven similarly.</p>
<p>In order to prove that <span class="math">\(L(f)\leq U(f)\)</span>, let <span class="math">\(Q,R\)</span> be any partitions and let <span class="math">\(P=Q\cup R\)</span>. Then <span class="math">\(L(Q,f)\leq L(P,f)\leq U(P,f)\leq U(R,f)\)</span>. Therefore any lower sum is less than or equal to any upper sum. In other words any lower sum is <strong>a</strong> lower bound for the set of all upper sums. Since <span class="math">\(U(f)\)</span> is the <strong>greatest</strong> lower bound for the set of all upper sums, we have <span class="math">\(L(P,f)\leq U(f)\)</span>. Since <span class="math">\(P\)</span> could be any partition, it follows that <span class="math">\(U(f)\)</span> is <strong>an</strong> upper bound for the set of all lower sums. Since <span class="math">\(L(f)\)</span> is the <strong>least</strong> upper bound for the set of all lower sums, <span class="math">\(L(f)\leq U(f)\)</span> follows.</p>
<p>In the above proofs we frequently used the fact that the refinement of a partition increases lower sums and decreases upper sums. The increase of lower sums and decrease of upper sums can be proven in the same way. In order to prove the increase of lower sums we can insert an additional point <span class="math">\(p\)</span> to the partition <span class="math">\(P\)</span> and call the refined partition <span class="math">\(P'\)</span> such that</p>
<div class="math">
\[P'=\lbrace x_0,x_1, ... , x _{k-1}, p, x_k, x _{k+1}, ..., x_n\rbrace\]</div>
<p>Let <span class="math">\(m'=\inf\lbrace x:x\in[x _{k-1}, p] \rbrace\)</span>, <span class="math">\(m''=\inf\lbrace x:x\in[p, x_k] \rbrace\)</span>, <span class="math">\(m_i=\inf\lbrace x:x\in[x_{i-1}, x_i] \rbrace\)</span>. It follows that <span class="math">\(m'\geq m_k\)</span> and <span class="math">\(m''\geq m_k\)</span>. Therefore</p>
<div class="math">
\[\begin{split}L(P',f)&amp;=\sum _{i=1}^{k-1}m_i(x_i-x _{i-1})+m'(p-x _{k-1})+m''(x_k-p)+\sum _{i=k+1}^n m_i(x_i-x _{i-1})\\
           &amp;\geq \sum _{i=1}^{k-1}m_i(x_i-x _{i-1})+m_k(p-x _{k-1})+m_k(x_k-p)+\sum _{i=k+1}^n m_i(x_i-x _{i-1})\\
           &amp;=\sum _{i=1}^{k-1}m_i(x_i-x _{i-1})+m_k(x_k-x _{k-1})+\sum _{i=k+1}^n m_i(x_i-x _{i-1})\\
           &amp;=L(P,f)\end{split}\]</div>
<p><strong>References</strong></p>
<p id="id1">[1] Muldowney, James S. ; “Mathematics 117 Lecture Notes”, University of Alberta</p>
<p id="id2">[2] Bowman, John C. ; &#8220;Math 117/118 Honours Calculus Lecture Notes&#8221;, University of Alberta</p>
<p id="id3">[3] <a class="reference external" href="http://planetmath.org/proofoflimitruleofproduct">http://planetmath.org/proofoflimitruleofproduct</a></p>
<p id="id4">[4] Thomas&#8217; Calculus, 12th edition.</p>
<p id="id5">[5] <a class="reference external" href="http://www.askamathematician.com/2010/12/q-what-does-00-zero-raised-to-the-zeroth-power-equal-why-do-mathematicians-and-high-school-teachers-disagree/">http://www.askamathematician.com/2010/12/q-what-does-00-zero-raised-to-the-zeroth-power-equal-why-do-mathematicians-and-high-school-teachers-disagree/</a></p>
<p id="id6">[6] Spivak M. (1965);&#8221;Calculus on Manifolds&#8221;, ISBN 0-8053-9021-9</p>
<p id="id7">[7] Rudin W. (1976);&#8221;Principles of Mathematical Analysis&#8221;, ISBN 0-07-054235-X</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
<h3><a href="index.html">Table Of Contents</a></h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="2DTruss.html">2D Truss System Solver</a></li>
<li class="toctree-l1"><a class="reference internal" href="2DFrame.html">2D Frame System Solver</a></li>
<li class="toctree-l1"><a class="reference internal" href="MachineLearning.html">Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="SiemensNX.html">3D Modeling Tutorials</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="">Calculus</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#vector-norm-and-inner-product">Vector norm and inner product</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#linear-independence">Linear independence</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#mean-value-theorem-and-rolle-s-theorem">Mean Value Theorem and Rolle&#8217;s Theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="#taylor-s-theorem">Taylor&#8217;s theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="#integration-by-parts">Integration by Parts</a></li>
<li class="toctree-l2"><a class="reference internal" href="#power-series">Power Series</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#direct-comparison-test">Direct Comparison Test</a></li>
<li class="toctree-l3"><a class="reference internal" href="#every-convergent-sequence-is-bounded">Every convergent sequence is bounded</a></li>
<li class="toctree-l3"><a class="reference internal" href="#limit-comparison-test">Limit Comparison Test</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ratio-test">Ratio Test</a></li>
<li class="toctree-l3"><a class="reference internal" href="#root-test">Root Test</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dirichlet-test">Dirichlet Test</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cauchy-convergence-criterion">Cauchy convergence criterion</a></li>
<li class="toctree-l3"><a class="reference internal" href="#abel-s-lemma">Abel&#8217;s Lemma</a></li>
<li class="toctree-l3"><a class="reference internal" href="#radius-of-convergence">Radius of convergence</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#l-hospital-s-rule">L&#8217;Hospital&#8217;s Rule</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cauchy-mean-value-theorem">Cauchy Mean Value Theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="#logarithm">Logarithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="#absolute-value">Absolute value</a></li>
<li class="toctree-l2"><a class="reference internal" href="#the-fundamental-theorem-of-calculus">The Fundamental Theorem of Calculus</a></li>
<li class="toctree-l2"><a class="reference internal" href="#differentiation-rules">Differentiation Rules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#the-product-rule">The Product Rule</a></li>
<li class="toctree-l3"><a class="reference internal" href="#the-chain-rule">The Chain Rule</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#binomial-theorem">Binomial theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="#weierstrass-maximum-minimum-theorem">Weierstrass maximum minimum theorem</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#mean-value-theorem-for-integrals">Mean Value Theorem for Integrals</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bolzano-intermediate-value-theorem">Bolzano intermediate value theorem</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#every-bounded-sequence-has-a-convergent-subsequence-bolzano-weierstrass">Every bounded sequence has a convergent subsequence (Bolzano-Weierstrass)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#a-continuous-function-is-integrable">A continuous function is integrable</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#cauchy-criterion-for-integrability">Cauchy criterion for integrability</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="WebGL_Tri.html">Polygon Meshing through Triangulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="CoutteOpenFoam.html">Flow Between Parallel Plates</a></li>
</ul>

        </div>
      </div>
      <div class="clearer"></div>
    </div>
  <div class="related bottom">
  <nav id="rellinks">
    <ul>
        <li>
          &larr;
          <a href="SiemensNX.html" title="Previous document">3D Modeling Tutorials</a>
        </li>
        <li>
          <a href="WebGL_Tri.html" title="Next document">Polygon Meshing through Triangulation</a>
          &rarr;
        </li>
    </ul>
  </nav>
  <nav id="breadcrumbs">
    <ul>
      <li><a href="index.html">Home</a></li> 
    </ul>
  </nav>
  </div>
  <footer id="pagefooter">&copy; 2015, Celal Cakiroglu.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a>
      1.2.2
        with the <a href="http://github.com/irskep/sphinx-better-theme">
          better</a> theme.

  </footer>

  
  </body>
</html>